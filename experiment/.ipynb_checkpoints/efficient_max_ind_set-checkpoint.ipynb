{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20ca5eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "def create_random_graph(n, min_neighbors, max_neighbors):\n",
    "    # Ensure that the sum of the degree sequence is even\n",
    "    while True:\n",
    "        degree_sequence = [random.randint(min_neighbors, max_neighbors) for _ in range(n)]\n",
    "        if sum(degree_sequence) % 2 == 0:\n",
    "            break\n",
    "\n",
    "    # Create a graph using the configuration model\n",
    "    G = nx.configuration_model(degree_sequence)\n",
    "\n",
    "    # Remove parallel edges and self-loops\n",
    "    G = nx.Graph(G)\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "\n",
    "    return nx.to_dict_of_lists(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "26d1b74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vertices_within_n_layers(graph, start_vertex, n, active_nodes):\n",
    "    \"\"\"\n",
    "    Get all vertices within 'n' layers from 'start_vertex'.\n",
    "    Only consider vertices that are in 'active_nodes'.\n",
    "    \"\"\"\n",
    "\n",
    "    visited = set([start_vertex])\n",
    "    frontier = set([start_vertex])\n",
    "\n",
    "    for _ in range(n):\n",
    "        next_frontier = set()\n",
    "        for vertex in frontier:\n",
    "            for neighbor in graph[vertex]:\n",
    "                if neighbor not in visited:\n",
    "                    visited.add(neighbor)\n",
    "                    next_frontier.add(neighbor)\n",
    "        frontier = next_frontier\n",
    "\n",
    "    return visited\n",
    "\n",
    "def maximal_n_apart_independent_set(graph, n, verbose=False):\n",
    "    \"\"\"\n",
    "    Find an n-apart independent set in the graph.\n",
    "    \"\"\"\n",
    "    independent_set = set()\n",
    "    active_nodes = set(graph.keys())\n",
    "\n",
    "    while active_nodes:\n",
    "        if verbose and len(active_nodes) % 1000 < 2:\n",
    "            print(\"[PROGRESS] maximal_n_apart_independent_set need to process\", len(active_nodes), \"more nodes.\") \n",
    "        current_vertex = random.choice(tuple(active_nodes))  # Choose a vertex from active nodes\n",
    "        active_nodes.remove(current_vertex)\n",
    "        independent_set.add(current_vertex)\n",
    "\n",
    "        # Get all vertices within n layers and mark them as inactive\n",
    "        to_deactivate = get_vertices_within_n_layers(graph, current_vertex, n, active_nodes)\n",
    "        active_nodes.difference_update(to_deactivate)\n",
    "\n",
    "    return independent_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "07143b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = create_random_graph(100000, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6d83eaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROGRESS] maximal_n_apart_independent_set need to process 100000 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 96001 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 84002 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 80001 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 79002 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 74000 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 71001 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 67001 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 58002 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 57002 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 57000 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 52002 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 50000 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 48001 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 48000 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 39001 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 37000 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 32002 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 31002 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 28002 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 27002 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 21000 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 19000 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 18001 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 17001 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 16001 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 14000 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 11002 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 10001 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 9002 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 8002 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 7000 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 6001 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 5002 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 4000 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 3002 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 3000 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 2001 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 2000 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 1002 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 1001 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 1000 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 2 more nodes.\n",
      "[PROGRESS] maximal_n_apart_independent_set need to process 1 more nodes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14384"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(maximal_n_apart_independent_set(g, 5, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48654f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 2 16 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
