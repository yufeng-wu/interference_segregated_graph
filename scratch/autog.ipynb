{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6604d37a",
   "metadata": {},
   "source": [
    "This notebook implements the Auto-G Computation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "5dbe2ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "e214dfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import util\n",
    "from main import data_generator as dg\n",
    "from main import maximal_independent_set\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "from scipy.optimize import minimize\n",
    "from scipy.integrate import quad\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "d1518299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_for_estimation(network, ind_set, sample):\n",
    "    '''Function to assemble data to estimate the distribution f(y | -) and f(l |-)'''\n",
    "    \n",
    "    data_list = []\n",
    "    \n",
    "    for i in ind_set['subject']:\n",
    "        # extract the relevant rows from sample based on index i. \n",
    "        row = sample.loc[i]\n",
    "        \n",
    "        # assuming 'Y', 'A', and 'L' are column names in 'sample'\n",
    "        l_i = row['L']\n",
    "        a_i = row['A']\n",
    "        y_i = row['Y']\n",
    "        \n",
    "        # get the neighbors of i\n",
    "        N_i = util.kth_order_neighborhood(network, i, 1)\n",
    "        normalizing_weight = 1 #/ len(N_i)\n",
    "        \n",
    "        # Get a list with sample.loc[j]['Y'] for each j in N_i\n",
    "        l_j = [sample.loc[j]['L'] for j in N_i]\n",
    "        a_j = [sample.loc[j]['A'] for j in N_i]\n",
    "        y_j = [sample.loc[j]['Y'] for j in N_i]\n",
    "        \n",
    "        # sum over l_j and then mutiply with normalizing_weight\n",
    "        sum_l_j = sum(l_j)\n",
    "        adjusted_sum_l_j = sum_l_j * normalizing_weight\n",
    "\n",
    "        sum_a_j = sum(a_j)\n",
    "        adjusted_sum_a_j = sum_a_j * normalizing_weight\n",
    "        \n",
    "        w_ij_y = normalizing_weight\n",
    "        w_ij_l = normalizing_weight\n",
    "        \n",
    "        data_list.append({\n",
    "            'i' : i,\n",
    "            'y_i': y_i,\n",
    "            'a_i': a_i,\n",
    "            'l_i': l_i,\n",
    "            'l_j_list': l_j,\n",
    "            'y_j_list': y_j,  \n",
    "            'adjusted_sum_l_j': adjusted_sum_l_j,\n",
    "            'adjusted_sum_a_j': adjusted_sum_a_j,\n",
    "            'w_ij_y': w_ij_yw_ij_theta,\n",
    "            'w_ij_l': w_ij_l \n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data_list) \n",
    "    return df     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "3b4615d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sketch\n",
    "\n",
    "# get network (UUU) data\n",
    "# find maximal_1_apart_independent_set\n",
    "# assemble Y_est_data using networkdata and indset\n",
    "\n",
    "# specify the form of the density f(yi | -)\n",
    "# specify the negative log-likelihood function\n",
    "# use scipy.optimize minimize to estmate tau_y\n",
    "# now plug tau_y hat back in we will get f(y | -)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "d22d926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR AUTO LOGISTIC MODEL ###\n",
    "\n",
    "\n",
    "### L ###\n",
    "def H_i(l_i, adjusted_sum_l_j, params):\n",
    "    beta_0, beta_1 = params\n",
    "    return beta_0 + beta_1*adjusted_sum_l_j\n",
    "\n",
    "def W_i(data_i, params, l_i=None):\n",
    "    # we allow the caller to pass in l_i separate from data_i\n",
    "    # so that when evaluating the denominator it is easier.\n",
    "    if l_i == None:\n",
    "        l_i = data_i['l_i']\n",
    "    H_i_output = H_i(l_i=l_i, \n",
    "                     adjusted_sum_l_j=data_i['adjusted_sum_l_j'], \n",
    "                     params=params)\n",
    "    \n",
    "    second_term = 0\n",
    "    for l_j in data_i['l_j_list']:\n",
    "        second_term += l_i * l_j * data_i['w_ij_l']\n",
    "    \n",
    "    return l_i * H_i_output + second_term\n",
    "\n",
    "def f_L_i_given_stuff(data_i, params):\n",
    "    numerator = math.exp(W_i(data_i, params))\n",
    "    \n",
    "    denominator = 0\n",
    "    for l_i_val in [0, 1]: # sum over all possible values of l_i (which is 1 and 0 cuz y is binary)\n",
    "        denominator += math.exp(W_i(data_i, params, l_i=l_i_val))\n",
    "    \n",
    "    return numerator / denominator\n",
    "\n",
    "\n",
    "### Y ###\n",
    "def G_i(y_i, a_i, l_i, adjusted_sum_a_j, adjusted_sum_l_j, params):\n",
    "    beta_0, beta_1, beta_2, beta_3, beta_4 = params[:-1]\n",
    "    return beta_0 + beta_1*a_i + beta_2*l_i + beta_3*adjusted_sum_a_j + beta_4*adjusted_sum_l_j\n",
    "\n",
    "def theta_ij(w_ij_y, params):\n",
    "    theta = params[-1]\n",
    "    return w_ij_y * theta\n",
    "\n",
    "def U_i(data_i, params, y_i=None):\n",
    "    # we allow the caller to pass in y_i separate from data_i\n",
    "    # so that when evaluating the denominator it is easier.\n",
    "    if y_i == None:\n",
    "        y_i = data_i['y_i']\n",
    "    G_i_output = G_i(y_i=y_i, \n",
    "                     a_i=data_i['a_i'], \n",
    "                     l_i=data_i['l_i'], \n",
    "                     adjusted_sum_a_j=data_i['adjusted_sum_a_j'], \n",
    "                     adjusted_sum_l_j=data_i['adjusted_sum_l_j'], \n",
    "                     params=params)\n",
    "    \n",
    "    second_term = 0\n",
    "    for y_j in data_i['y_j_list']:\n",
    "        second_term += y_i * y_j * theta_ij(data_i['w_ij_y'], params)\n",
    "    \n",
    "    return y_i * G_i_output + second_term\n",
    "\n",
    "def f_Y_i_given_stuff(data_i, params):\n",
    "    numerator = math.exp(U_i(data_i, params))\n",
    "    \n",
    "    denominator = 0\n",
    "    for y_i_val in [0, 1]: # sum over all possible values of y_i (which is 1 and 0 cuz y is binary)\n",
    "        denominator += math.exp(U_i(data_i, params, y_i=y_i_val))\n",
    "    \n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "4a13f92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlcl(params, f, est_df):\n",
    "    '''\n",
    "    negative log coding likelihood\n",
    "    f: a function, either f_Y_i_given_stuff or f_L_i_given_stuff\n",
    "    '''\n",
    "    log_likelihoods = est_df.apply(lambda row: np.log(f(row, params)), axis=1)\n",
    "    return -np.sum(log_likelihoods)\n",
    "\n",
    "def optimize_params(nll_function, initial_params, f, est_df):\n",
    "    result = minimize(nll_function, x0=initial_params, args=(f, est_df))\n",
    "    return result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "11d45b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_sampler_1(n_samples, burn_in, network, f_Yi, f_Li, verbose, A_val):\n",
    "    '''\n",
    "    This implementation closely follows the description on page 10 of the auto-g paper.\n",
    "    '''\n",
    "    samples = []\n",
    "    N = len(network) # number of subjects in the network\n",
    "    \n",
    "    # produce initial random guess\n",
    "    sample = pd.DataFrame(index=network.keys(), columns=['L', 'A', 'Y'])\n",
    "    sample['L'] = {vertex: random.choice([1, 0]) for vertex in network.keys()}\n",
    "    sample['A'] = {vertex: A_val for vertex in network.keys()}\n",
    "    sample['Y'] = {vertex: random.choice([1, 0]) for vertex in network.keys()}\n",
    "\n",
    "    for m in range(n_samples + burn_in):\n",
    "        if verbose and m % 1000 == 0:\n",
    "            print(\"progress: \", m / (n_samples + burn_in))\n",
    "            \n",
    "        i = (m % N) # the paper has \"+1\" but i don't +1 because the index of subjects in my network starts from 0\n",
    "        # draw L_i ~ f(L_i | L_-i)\n",
    "        boundary_values_L = {\n",
    "            'L_neighbors': [sample.loc[neighbor, 'L'] for neighbor in network[i]]\n",
    "        }\n",
    "        new_Li = draw(dist=f_Li, inputs=boundary_values_L)\n",
    "        \n",
    "        # draw Y_i ~ f(Y_i | Y_-i)\n",
    "        boundary_values_Y = {\n",
    "            'L_self': sample.loc[i, 'L'],\n",
    "            'L_neighbors': [sample.loc[neighbor, 'L'] for neighbor in network[i]],\n",
    "            'A_self': sample.loc[i, 'A'],\n",
    "            'A_neighbors': [sample.loc[neighbor, 'A'] for neighbor in network[i]],\n",
    "            'Y_neighbors': [sample.loc[neighbor, 'Y'] for neighbor in network[i]],\n",
    "        }\n",
    "        new_Yi = draw(dist=f_Yi, inputs=boundary_values_Y)\n",
    "\n",
    "        sample.loc[i, 'L'] = new_Li\n",
    "        sample.loc[i, 'Y'] = new_Yi\n",
    "\n",
    "        if m >= burn_in:\n",
    "            samples.append(sample.copy())\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "29415c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_i_a(samples, i, select_for_every):\n",
    "    '''\n",
    "    samples: samples from gibbs_sampler_1\n",
    "    select_for_every: compute the causal effect using samples for every select_for_every iterations \n",
    "                      to \"thin\" autocorrelation\n",
    "    '''\n",
    "    \n",
    "    selected_Y_values = []\n",
    "    \n",
    "    # Iterate through the samples, selecting every nth sample where n is select_for_every\n",
    "    for sample_idx in range(0, len(samples), select_for_every):\n",
    "        selected_sample = samples[sample_idx]\n",
    "        selected_Y_values.append(selected_sample.loc[i, 'Y'])\n",
    "        \n",
    "    average_Y = float(sum(selected_Y_values) / len(selected_Y_values))\n",
    "    return average_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "7f794c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(dist, inputs):\n",
    "    proba_of_1 = dist(inputs)\n",
    "    return np.random.binomial(1, proba_of_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "08b680ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_given_boundary_binary(boundary_values):\n",
    "    '''\n",
    "    Note: This can't be any random function. \n",
    "          Check Lauritzen chain graph paper page 342.\n",
    "    '''\n",
    "    weighted_sum = 0\n",
    "    weights = {\n",
    "        'Y_neighbors': -0.1, # this need to be controlled\n",
    "        'L_self': 0.8,\n",
    "        'A_self': 1.7,\n",
    "        'L_neighbors': -0.1, # this need to be controlled\n",
    "        'A_neighbors': -0.1 # this need to be controlled\n",
    "    }\n",
    "    \n",
    "    for key, values in boundary_values.items():\n",
    "        if values is not None and values != []:\n",
    "            if isinstance(values, list):\n",
    "                weighted_sum += weights[key] * sum(values)\n",
    "            else:\n",
    "                weighted_sum += weights[key] * values\n",
    "\n",
    "    noise = np.random.normal(0, 0.1)\n",
    "    p = expit(weighted_sum + noise)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "755913d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2m/s6xvfp8x29j9m9pl6w7jn8hh0000gn/T/ipykernel_56562/2532712610.py:16: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if values is not None and values != []:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress:  0.02\n",
      "progress:  0.04\n",
      "progress:  0.06\n",
      "progress:  0.08\n",
      "progress:  0.1\n",
      "progress:  0.12\n",
      "progress:  0.14\n",
      "progress:  0.16\n",
      "progress:  0.18\n",
      "progress:  0.2\n",
      "progress:  0.22\n",
      "progress:  0.24\n",
      "progress:  0.26\n",
      "progress:  0.28\n",
      "progress:  0.3\n",
      "progress:  0.32\n",
      "progress:  0.34\n",
      "progress:  0.36\n",
      "progress:  0.38\n",
      "progress:  0.4\n",
      "progress:  0.42\n",
      "progress:  0.44\n",
      "progress:  0.46\n",
      "progress:  0.48\n",
      "progress:  0.5\n",
      "progress:  0.52\n",
      "progress:  0.54\n",
      "progress:  0.56\n",
      "progress:  0.58\n",
      "progress:  0.6\n",
      "progress:  0.62\n",
      "progress:  0.64\n",
      "progress:  0.66\n",
      "progress:  0.68\n",
      "progress:  0.7\n",
      "progress:  0.72\n",
      "progress:  0.74\n",
      "progress:  0.76\n",
      "progress:  0.78\n",
      "progress:  0.8\n",
      "progress:  0.82\n",
      "progress:  0.84\n",
      "progress:  0.86\n",
      "progress:  0.88\n",
      "progress:  0.9\n",
      "progress:  0.92\n",
      "progress:  0.94\n",
      "progress:  0.96\n",
      "progress:  0.98\n",
      "progress:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2m/s6xvfp8x29j9m9pl6w7jn8hh0000gn/T/ipykernel_56562/2532712610.py:16: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if values is not None and values != []:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress:  0.02\n",
      "progress:  0.04\n",
      "progress:  0.06\n",
      "progress:  0.08\n",
      "progress:  0.1\n",
      "progress:  0.12\n",
      "progress:  0.14\n",
      "progress:  0.16\n",
      "progress:  0.18\n",
      "progress:  0.2\n",
      "progress:  0.22\n",
      "progress:  0.24\n",
      "progress:  0.26\n",
      "progress:  0.28\n",
      "progress:  0.3\n",
      "progress:  0.32\n",
      "progress:  0.34\n",
      "progress:  0.36\n",
      "progress:  0.38\n",
      "progress:  0.4\n",
      "progress:  0.42\n",
      "progress:  0.44\n",
      "progress:  0.46\n",
      "progress:  0.48\n",
      "progress:  0.5\n",
      "progress:  0.52\n",
      "progress:  0.54\n",
      "progress:  0.56\n",
      "progress:  0.58\n",
      "progress:  0.6\n",
      "progress:  0.62\n",
      "progress:  0.64\n",
      "progress:  0.66\n",
      "progress:  0.68\n",
      "progress:  0.7\n",
      "progress:  0.72\n",
      "progress:  0.74\n",
      "progress:  0.76\n",
      "progress:  0.78\n",
      "progress:  0.8\n",
      "progress:  0.82\n",
      "progress:  0.84\n",
      "progress:  0.86\n",
      "progress:  0.88\n",
      "progress:  0.9\n",
      "progress:  0.92\n",
      "progress:  0.94\n",
      "progress:  0.96\n",
      "progress:  0.98\n"
     ]
    }
   ],
   "source": [
    "# steps to test for the correctness of auto g\n",
    "\n",
    "# generate a small network n\n",
    "network = util.create_random_network(n=1000, min_neighbors=1, max_neighbors=6)\n",
    "\n",
    "# evaluate true causal effect using true f_Yi, true f_Li, n, and A_val (via beta_i_a and gibbs sampler 1)\n",
    "true_f_Yi = sample_given_boundary_binary\n",
    "true_f_Li = sample_given_boundary_binary\n",
    "\n",
    "Y_A1 = gibbs_sampler_1(n_samples=40000, burn_in=10000, network=network, f_Yi=true_f_Yi, f_Li=true_f_Li, \n",
    "                       verbose=True, A_val=1)\n",
    "\n",
    "Y_A0 = gibbs_sampler_1(n_samples=40000, burn_in=10000, network=network, f_Yi=true_f_Yi, f_Li=true_f_Li, \n",
    "                       verbose=True, A_val=0)\n",
    "\n",
    "# generate a UUU realization based on the structure of n\n",
    "# estmate f_Yi hat, f_Li hat using auto_g & network realization\n",
    "# estimate causal effect using f_Yi hat, f_Li hat, n, and A_val (via beta_i_a and gibbs sampler 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "08558898",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = [beta_i_a(Y_A1, i, 3) - beta_i_a(Y_A0, i, 3) for i in range(0, 1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "65e2f8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0722229638518074"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "47d0d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_edge_types(true_model):\n",
    "    # Build edge_types based on edge types at each layer\n",
    "    edge_types = {}\n",
    "\n",
    "    if true_model[0] == 'U': \n",
    "        edge_types['L'] = ['U', {'sample_given_boundary':dg.sample_given_boundary_binary, 'verbose':VERBOSE, 'burn_in':BURN_IN}]\n",
    "    else:\n",
    "        edge_types['L'] = ['B', {'U_dist':dg.U_dist_1, 'f':dg.f_binary}]\n",
    "\n",
    "    if true_model[1] == 'U': \n",
    "        edge_types['A'] = ['U', {'sample_given_boundary':dg.sample_given_boundary_binary, 'verbose':VERBOSE, 'burn_in':BURN_IN}]\n",
    "    else:\n",
    "        edge_types['A'] = ['B', {'U_dist':dg.U_dist_1, 'f':dg.f_binary}]\n",
    "\n",
    "    if true_model[2] == 'U': \n",
    "        edge_types['Y'] = ['U', {'sample_given_boundary':dg.sample_given_boundary_binary, 'verbose':VERBOSE, 'burn_in':BURN_IN}]\n",
    "    else:\n",
    "        edge_types['Y'] = ['B', {'U_dist':dg.U_dist_1, 'f':dg.f_binary}]\n",
    "\n",
    "    return edge_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "c0bde5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROGRESS] Sample from UG burning in: 0 / 300\n",
      "[PROGRESS] Sample from UG burning in: 1 / 300\n",
      "[PROGRESS] Sample from UG burning in: 2 / 300\n",
      "[PROGRESS] Sample from UG burning in: 3 / 300\n",
      "[PROGRESS] Sample from UG burning in: 4 / 300\n",
      "[PROGRESS] Sample from UG burning in: 5 / 300\n",
      "[PROGRESS] Sample from UG burning in: 6 / 300\n",
      "[PROGRESS] Sample from UG burning in: 7 / 300\n",
      "[PROGRESS] Sample from UG burning in: 8 / 300\n",
      "[PROGRESS] Sample from UG burning in: 9 / 300\n",
      "[PROGRESS] Sample from UG burning in: 10 / 300\n",
      "[PROGRESS] Sample from UG burning in: 11 / 300\n",
      "[PROGRESS] Sample from UG burning in: 12 / 300\n",
      "[PROGRESS] Sample from UG burning in: 13 / 300\n",
      "[PROGRESS] Sample from UG burning in: 14 / 300\n",
      "[PROGRESS] Sample from UG burning in: 15 / 300\n",
      "[PROGRESS] Sample from UG burning in: 16 / 300\n",
      "[PROGRESS] Sample from UG burning in: 17 / 300\n",
      "[PROGRESS] Sample from UG burning in: 18 / 300\n",
      "[PROGRESS] Sample from UG burning in: 19 / 300\n",
      "[PROGRESS] Sample from UG burning in: 20 / 300\n",
      "[PROGRESS] Sample from UG burning in: 21 / 300\n",
      "[PROGRESS] Sample from UG burning in: 22 / 300\n",
      "[PROGRESS] Sample from UG burning in: 23 / 300\n",
      "[PROGRESS] Sample from UG burning in: 24 / 300\n",
      "[PROGRESS] Sample from UG burning in: 25 / 300\n",
      "[PROGRESS] Sample from UG burning in: 26 / 300\n",
      "[PROGRESS] Sample from UG burning in: 27 / 300\n",
      "[PROGRESS] Sample from UG burning in: 28 / 300\n",
      "[PROGRESS] Sample from UG burning in: 29 / 300\n",
      "[PROGRESS] Sample from UG burning in: 30 / 300\n",
      "[PROGRESS] Sample from UG burning in: 31 / 300\n",
      "[PROGRESS] Sample from UG burning in: 32 / 300\n",
      "[PROGRESS] Sample from UG burning in: 33 / 300\n",
      "[PROGRESS] Sample from UG burning in: 34 / 300\n",
      "[PROGRESS] Sample from UG burning in: 35 / 300\n",
      "[PROGRESS] Sample from UG burning in: 36 / 300\n",
      "[PROGRESS] Sample from UG burning in: 37 / 300\n",
      "[PROGRESS] Sample from UG burning in: 38 / 300\n",
      "[PROGRESS] Sample from UG burning in: 39 / 300\n",
      "[PROGRESS] Sample from UG burning in: 40 / 300\n",
      "[PROGRESS] Sample from UG burning in: 41 / 300\n",
      "[PROGRESS] Sample from UG burning in: 42 / 300\n",
      "[PROGRESS] Sample from UG burning in: 43 / 300\n",
      "[PROGRESS] Sample from UG burning in: 44 / 300\n",
      "[PROGRESS] Sample from UG burning in: 45 / 300\n",
      "[PROGRESS] Sample from UG burning in: 46 / 300\n",
      "[PROGRESS] Sample from UG burning in: 47 / 300\n",
      "[PROGRESS] Sample from UG burning in: 48 / 300\n",
      "[PROGRESS] Sample from UG burning in: 49 / 300\n",
      "[PROGRESS] Sample from UG burning in: 50 / 300\n",
      "[PROGRESS] Sample from UG burning in: 51 / 300\n",
      "[PROGRESS] Sample from UG burning in: 52 / 300\n",
      "[PROGRESS] Sample from UG burning in: 53 / 300\n",
      "[PROGRESS] Sample from UG burning in: 54 / 300\n",
      "[PROGRESS] Sample from UG burning in: 55 / 300\n",
      "[PROGRESS] Sample from UG burning in: 56 / 300\n",
      "[PROGRESS] Sample from UG burning in: 57 / 300\n",
      "[PROGRESS] Sample from UG burning in: 58 / 300\n",
      "[PROGRESS] Sample from UG burning in: 59 / 300\n",
      "[PROGRESS] Sample from UG burning in: 60 / 300\n",
      "[PROGRESS] Sample from UG burning in: 61 / 300\n",
      "[PROGRESS] Sample from UG burning in: 62 / 300\n",
      "[PROGRESS] Sample from UG burning in: 63 / 300\n",
      "[PROGRESS] Sample from UG burning in: 64 / 300\n",
      "[PROGRESS] Sample from UG burning in: 65 / 300\n",
      "[PROGRESS] Sample from UG burning in: 66 / 300\n",
      "[PROGRESS] Sample from UG burning in: 67 / 300\n",
      "[PROGRESS] Sample from UG burning in: 68 / 300\n",
      "[PROGRESS] Sample from UG burning in: 69 / 300\n",
      "[PROGRESS] Sample from UG burning in: 70 / 300\n",
      "[PROGRESS] Sample from UG burning in: 71 / 300\n",
      "[PROGRESS] Sample from UG burning in: 72 / 300\n",
      "[PROGRESS] Sample from UG burning in: 73 / 300\n",
      "[PROGRESS] Sample from UG burning in: 74 / 300\n",
      "[PROGRESS] Sample from UG burning in: 75 / 300\n",
      "[PROGRESS] Sample from UG burning in: 76 / 300\n",
      "[PROGRESS] Sample from UG burning in: 77 / 300\n",
      "[PROGRESS] Sample from UG burning in: 78 / 300\n",
      "[PROGRESS] Sample from UG burning in: 79 / 300\n",
      "[PROGRESS] Sample from UG burning in: 80 / 300\n",
      "[PROGRESS] Sample from UG burning in: 81 / 300\n",
      "[PROGRESS] Sample from UG burning in: 82 / 300\n",
      "[PROGRESS] Sample from UG burning in: 83 / 300\n",
      "[PROGRESS] Sample from UG burning in: 84 / 300\n",
      "[PROGRESS] Sample from UG burning in: 85 / 300\n",
      "[PROGRESS] Sample from UG burning in: 86 / 300\n",
      "[PROGRESS] Sample from UG burning in: 87 / 300\n",
      "[PROGRESS] Sample from UG burning in: 88 / 300\n",
      "[PROGRESS] Sample from UG burning in: 89 / 300\n",
      "[PROGRESS] Sample from UG burning in: 90 / 300\n",
      "[PROGRESS] Sample from UG burning in: 91 / 300\n",
      "[PROGRESS] Sample from UG burning in: 92 / 300\n",
      "[PROGRESS] Sample from UG burning in: 93 / 300\n",
      "[PROGRESS] Sample from UG burning in: 94 / 300\n",
      "[PROGRESS] Sample from UG burning in: 95 / 300\n",
      "[PROGRESS] Sample from UG burning in: 96 / 300\n",
      "[PROGRESS] Sample from UG burning in: 97 / 300\n",
      "[PROGRESS] Sample from UG burning in: 98 / 300\n",
      "[PROGRESS] Sample from UG burning in: 99 / 300\n",
      "[PROGRESS] Sample from UG burning in: 100 / 300\n",
      "[PROGRESS] Sample from UG burning in: 101 / 300\n",
      "[PROGRESS] Sample from UG burning in: 102 / 300\n",
      "[PROGRESS] Sample from UG burning in: 103 / 300\n",
      "[PROGRESS] Sample from UG burning in: 104 / 300\n",
      "[PROGRESS] Sample from UG burning in: 105 / 300\n",
      "[PROGRESS] Sample from UG burning in: 106 / 300\n",
      "[PROGRESS] Sample from UG burning in: 107 / 300\n",
      "[PROGRESS] Sample from UG burning in: 108 / 300\n",
      "[PROGRESS] Sample from UG burning in: 109 / 300\n",
      "[PROGRESS] Sample from UG burning in: 110 / 300\n",
      "[PROGRESS] Sample from UG burning in: 111 / 300\n",
      "[PROGRESS] Sample from UG burning in: 112 / 300\n",
      "[PROGRESS] Sample from UG burning in: 113 / 300\n",
      "[PROGRESS] Sample from UG burning in: 114 / 300\n",
      "[PROGRESS] Sample from UG burning in: 115 / 300\n",
      "[PROGRESS] Sample from UG burning in: 116 / 300\n",
      "[PROGRESS] Sample from UG burning in: 117 / 300\n",
      "[PROGRESS] Sample from UG burning in: 118 / 300\n",
      "[PROGRESS] Sample from UG burning in: 119 / 300\n",
      "[PROGRESS] Sample from UG burning in: 120 / 300\n",
      "[PROGRESS] Sample from UG burning in: 121 / 300\n",
      "[PROGRESS] Sample from UG burning in: 122 / 300\n",
      "[PROGRESS] Sample from UG burning in: 123 / 300\n",
      "[PROGRESS] Sample from UG burning in: 124 / 300\n",
      "[PROGRESS] Sample from UG burning in: 125 / 300\n",
      "[PROGRESS] Sample from UG burning in: 126 / 300\n",
      "[PROGRESS] Sample from UG burning in: 127 / 300\n",
      "[PROGRESS] Sample from UG burning in: 128 / 300\n",
      "[PROGRESS] Sample from UG burning in: 129 / 300\n",
      "[PROGRESS] Sample from UG burning in: 130 / 300\n",
      "[PROGRESS] Sample from UG burning in: 131 / 300\n",
      "[PROGRESS] Sample from UG burning in: 132 / 300\n",
      "[PROGRESS] Sample from UG burning in: 133 / 300\n",
      "[PROGRESS] Sample from UG burning in: 134 / 300\n",
      "[PROGRESS] Sample from UG burning in: 135 / 300\n",
      "[PROGRESS] Sample from UG burning in: 136 / 300\n",
      "[PROGRESS] Sample from UG burning in: 137 / 300\n",
      "[PROGRESS] Sample from UG burning in: 138 / 300\n",
      "[PROGRESS] Sample from UG burning in: 139 / 300\n",
      "[PROGRESS] Sample from UG burning in: 140 / 300\n",
      "[PROGRESS] Sample from UG burning in: 141 / 300\n",
      "[PROGRESS] Sample from UG burning in: 142 / 300\n",
      "[PROGRESS] Sample from UG burning in: 143 / 300\n",
      "[PROGRESS] Sample from UG burning in: 144 / 300\n",
      "[PROGRESS] Sample from UG burning in: 145 / 300\n",
      "[PROGRESS] Sample from UG burning in: 146 / 300\n",
      "[PROGRESS] Sample from UG burning in: 147 / 300\n",
      "[PROGRESS] Sample from UG burning in: 148 / 300\n",
      "[PROGRESS] Sample from UG burning in: 149 / 300\n",
      "[PROGRESS] Sample from UG burning in: 150 / 300\n",
      "[PROGRESS] Sample from UG burning in: 151 / 300\n",
      "[PROGRESS] Sample from UG burning in: 152 / 300\n",
      "[PROGRESS] Sample from UG burning in: 153 / 300\n",
      "[PROGRESS] Sample from UG burning in: 154 / 300\n",
      "[PROGRESS] Sample from UG burning in: 155 / 300\n",
      "[PROGRESS] Sample from UG burning in: 156 / 300\n",
      "[PROGRESS] Sample from UG burning in: 157 / 300\n",
      "[PROGRESS] Sample from UG burning in: 158 / 300\n",
      "[PROGRESS] Sample from UG burning in: 159 / 300\n",
      "[PROGRESS] Sample from UG burning in: 160 / 300\n",
      "[PROGRESS] Sample from UG burning in: 161 / 300\n",
      "[PROGRESS] Sample from UG burning in: 162 / 300\n",
      "[PROGRESS] Sample from UG burning in: 163 / 300\n",
      "[PROGRESS] Sample from UG burning in: 164 / 300\n",
      "[PROGRESS] Sample from UG burning in: 165 / 300\n",
      "[PROGRESS] Sample from UG burning in: 166 / 300\n",
      "[PROGRESS] Sample from UG burning in: 167 / 300\n",
      "[PROGRESS] Sample from UG burning in: 168 / 300\n",
      "[PROGRESS] Sample from UG burning in: 169 / 300\n",
      "[PROGRESS] Sample from UG burning in: 170 / 300\n",
      "[PROGRESS] Sample from UG burning in: 171 / 300\n",
      "[PROGRESS] Sample from UG burning in: 172 / 300\n",
      "[PROGRESS] Sample from UG burning in: 173 / 300\n",
      "[PROGRESS] Sample from UG burning in: 174 / 300\n",
      "[PROGRESS] Sample from UG burning in: 175 / 300\n",
      "[PROGRESS] Sample from UG burning in: 176 / 300\n",
      "[PROGRESS] Sample from UG burning in: 177 / 300\n",
      "[PROGRESS] Sample from UG burning in: 178 / 300\n",
      "[PROGRESS] Sample from UG burning in: 179 / 300\n",
      "[PROGRESS] Sample from UG burning in: 180 / 300\n",
      "[PROGRESS] Sample from UG burning in: 181 / 300\n",
      "[PROGRESS] Sample from UG burning in: 182 / 300\n",
      "[PROGRESS] Sample from UG burning in: 183 / 300\n",
      "[PROGRESS] Sample from UG burning in: 184 / 300\n",
      "[PROGRESS] Sample from UG burning in: 185 / 300\n",
      "[PROGRESS] Sample from UG burning in: 186 / 300\n",
      "[PROGRESS] Sample from UG burning in: 187 / 300\n",
      "[PROGRESS] Sample from UG burning in: 188 / 300\n",
      "[PROGRESS] Sample from UG burning in: 189 / 300\n",
      "[PROGRESS] Sample from UG burning in: 190 / 300\n",
      "[PROGRESS] Sample from UG burning in: 191 / 300\n",
      "[PROGRESS] Sample from UG burning in: 192 / 300\n",
      "[PROGRESS] Sample from UG burning in: 193 / 300\n",
      "[PROGRESS] Sample from UG burning in: 194 / 300\n",
      "[PROGRESS] Sample from UG burning in: 195 / 300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROGRESS] Sample from UG burning in: 196 / 300\n",
      "[PROGRESS] Sample from UG burning in: 197 / 300\n",
      "[PROGRESS] Sample from UG burning in: 198 / 300\n",
      "[PROGRESS] Sample from UG burning in: 199 / 300\n",
      "[PROGRESS] Sample from UG burning in: 200 / 300\n",
      "[PROGRESS] Sample from UG burning in: 201 / 300\n",
      "[PROGRESS] Sample from UG burning in: 202 / 300\n",
      "[PROGRESS] Sample from UG burning in: 203 / 300\n",
      "[PROGRESS] Sample from UG burning in: 204 / 300\n",
      "[PROGRESS] Sample from UG burning in: 205 / 300\n",
      "[PROGRESS] Sample from UG burning in: 206 / 300\n",
      "[PROGRESS] Sample from UG burning in: 207 / 300\n",
      "[PROGRESS] Sample from UG burning in: 208 / 300\n",
      "[PROGRESS] Sample from UG burning in: 209 / 300\n",
      "[PROGRESS] Sample from UG burning in: 210 / 300\n",
      "[PROGRESS] Sample from UG burning in: 211 / 300\n",
      "[PROGRESS] Sample from UG burning in: 212 / 300\n",
      "[PROGRESS] Sample from UG burning in: 213 / 300\n",
      "[PROGRESS] Sample from UG burning in: 214 / 300\n",
      "[PROGRESS] Sample from UG burning in: 215 / 300\n",
      "[PROGRESS] Sample from UG burning in: 216 / 300\n",
      "[PROGRESS] Sample from UG burning in: 217 / 300\n",
      "[PROGRESS] Sample from UG burning in: 218 / 300\n",
      "[PROGRESS] Sample from UG burning in: 219 / 300\n",
      "[PROGRESS] Sample from UG burning in: 220 / 300\n",
      "[PROGRESS] Sample from UG burning in: 221 / 300\n",
      "[PROGRESS] Sample from UG burning in: 222 / 300\n",
      "[PROGRESS] Sample from UG burning in: 223 / 300\n",
      "[PROGRESS] Sample from UG burning in: 224 / 300\n",
      "[PROGRESS] Sample from UG burning in: 225 / 300\n",
      "[PROGRESS] Sample from UG burning in: 226 / 300\n",
      "[PROGRESS] Sample from UG burning in: 227 / 300\n",
      "[PROGRESS] Sample from UG burning in: 228 / 300\n",
      "[PROGRESS] Sample from UG burning in: 229 / 300\n",
      "[PROGRESS] Sample from UG burning in: 230 / 300\n",
      "[PROGRESS] Sample from UG burning in: 231 / 300\n",
      "[PROGRESS] Sample from UG burning in: 232 / 300\n",
      "[PROGRESS] Sample from UG burning in: 233 / 300\n",
      "[PROGRESS] Sample from UG burning in: 234 / 300\n",
      "[PROGRESS] Sample from UG burning in: 235 / 300\n",
      "[PROGRESS] Sample from UG burning in: 236 / 300\n",
      "[PROGRESS] Sample from UG burning in: 237 / 300\n",
      "[PROGRESS] Sample from UG burning in: 238 / 300\n",
      "[PROGRESS] Sample from UG burning in: 239 / 300\n",
      "[PROGRESS] Sample from UG burning in: 240 / 300\n",
      "[PROGRESS] Sample from UG burning in: 241 / 300\n",
      "[PROGRESS] Sample from UG burning in: 242 / 300\n",
      "[PROGRESS] Sample from UG burning in: 243 / 300\n",
      "[PROGRESS] Sample from UG burning in: 244 / 300\n",
      "[PROGRESS] Sample from UG burning in: 245 / 300\n",
      "[PROGRESS] Sample from UG burning in: 246 / 300\n",
      "[PROGRESS] Sample from UG burning in: 247 / 300\n",
      "[PROGRESS] Sample from UG burning in: 248 / 300\n",
      "[PROGRESS] Sample from UG burning in: 249 / 300\n",
      "[PROGRESS] Sample from UG burning in: 250 / 300\n",
      "[PROGRESS] Sample from UG burning in: 251 / 300\n",
      "[PROGRESS] Sample from UG burning in: 252 / 300\n",
      "[PROGRESS] Sample from UG burning in: 253 / 300\n",
      "[PROGRESS] Sample from UG burning in: 254 / 300\n",
      "[PROGRESS] Sample from UG burning in: 255 / 300\n",
      "[PROGRESS] Sample from UG burning in: 256 / 300\n",
      "[PROGRESS] Sample from UG burning in: 257 / 300\n",
      "[PROGRESS] Sample from UG burning in: 258 / 300\n",
      "[PROGRESS] Sample from UG burning in: 259 / 300\n",
      "[PROGRESS] Sample from UG burning in: 260 / 300\n",
      "[PROGRESS] Sample from UG burning in: 261 / 300\n",
      "[PROGRESS] Sample from UG burning in: 262 / 300\n",
      "[PROGRESS] Sample from UG burning in: 263 / 300\n",
      "[PROGRESS] Sample from UG burning in: 264 / 300\n",
      "[PROGRESS] Sample from UG burning in: 265 / 300\n",
      "[PROGRESS] Sample from UG burning in: 266 / 300\n",
      "[PROGRESS] Sample from UG burning in: 267 / 300\n",
      "[PROGRESS] Sample from UG burning in: 268 / 300\n",
      "[PROGRESS] Sample from UG burning in: 269 / 300\n",
      "[PROGRESS] Sample from UG burning in: 270 / 300\n",
      "[PROGRESS] Sample from UG burning in: 271 / 300\n",
      "[PROGRESS] Sample from UG burning in: 272 / 300\n",
      "[PROGRESS] Sample from UG burning in: 273 / 300\n",
      "[PROGRESS] Sample from UG burning in: 274 / 300\n",
      "[PROGRESS] Sample from UG burning in: 275 / 300\n",
      "[PROGRESS] Sample from UG burning in: 276 / 300\n",
      "[PROGRESS] Sample from UG burning in: 277 / 300\n",
      "[PROGRESS] Sample from UG burning in: 278 / 300\n",
      "[PROGRESS] Sample from UG burning in: 279 / 300\n",
      "[PROGRESS] Sample from UG burning in: 280 / 300\n",
      "[PROGRESS] Sample from UG burning in: 281 / 300\n",
      "[PROGRESS] Sample from UG burning in: 282 / 300\n",
      "[PROGRESS] Sample from UG burning in: 283 / 300\n",
      "[PROGRESS] Sample from UG burning in: 284 / 300\n",
      "[PROGRESS] Sample from UG burning in: 285 / 300\n",
      "[PROGRESS] Sample from UG burning in: 286 / 300\n",
      "[PROGRESS] Sample from UG burning in: 287 / 300\n",
      "[PROGRESS] Sample from UG burning in: 288 / 300\n",
      "[PROGRESS] Sample from UG burning in: 289 / 300\n",
      "[PROGRESS] Sample from UG burning in: 290 / 300\n",
      "[PROGRESS] Sample from UG burning in: 291 / 300\n",
      "[PROGRESS] Sample from UG burning in: 292 / 300\n",
      "[PROGRESS] Sample from UG burning in: 293 / 300\n",
      "[PROGRESS] Sample from UG burning in: 294 / 300\n",
      "[PROGRESS] Sample from UG burning in: 295 / 300\n",
      "[PROGRESS] Sample from UG burning in: 296 / 300\n",
      "[PROGRESS] Sample from UG burning in: 297 / 300\n",
      "[PROGRESS] Sample from UG burning in: 298 / 300\n",
      "[PROGRESS] Sample from UG burning in: 299 / 300\n",
      "[PROGRESS] Sample from UG burning in: 0 / 300\n",
      "[PROGRESS] Sample from UG burning in: 1 / 300\n",
      "[PROGRESS] Sample from UG burning in: 2 / 300\n",
      "[PROGRESS] Sample from UG burning in: 3 / 300\n",
      "[PROGRESS] Sample from UG burning in: 4 / 300\n",
      "[PROGRESS] Sample from UG burning in: 5 / 300\n",
      "[PROGRESS] Sample from UG burning in: 6 / 300\n",
      "[PROGRESS] Sample from UG burning in: 7 / 300\n",
      "[PROGRESS] Sample from UG burning in: 8 / 300\n",
      "[PROGRESS] Sample from UG burning in: 9 / 300\n",
      "[PROGRESS] Sample from UG burning in: 10 / 300\n",
      "[PROGRESS] Sample from UG burning in: 11 / 300\n",
      "[PROGRESS] Sample from UG burning in: 12 / 300\n",
      "[PROGRESS] Sample from UG burning in: 13 / 300\n",
      "[PROGRESS] Sample from UG burning in: 14 / 300\n",
      "[PROGRESS] Sample from UG burning in: 15 / 300\n",
      "[PROGRESS] Sample from UG burning in: 16 / 300\n",
      "[PROGRESS] Sample from UG burning in: 17 / 300\n",
      "[PROGRESS] Sample from UG burning in: 18 / 300\n",
      "[PROGRESS] Sample from UG burning in: 19 / 300\n",
      "[PROGRESS] Sample from UG burning in: 20 / 300\n",
      "[PROGRESS] Sample from UG burning in: 21 / 300\n",
      "[PROGRESS] Sample from UG burning in: 22 / 300\n",
      "[PROGRESS] Sample from UG burning in: 23 / 300\n",
      "[PROGRESS] Sample from UG burning in: 24 / 300\n",
      "[PROGRESS] Sample from UG burning in: 25 / 300\n",
      "[PROGRESS] Sample from UG burning in: 26 / 300\n",
      "[PROGRESS] Sample from UG burning in: 27 / 300\n",
      "[PROGRESS] Sample from UG burning in: 28 / 300\n",
      "[PROGRESS] Sample from UG burning in: 29 / 300\n",
      "[PROGRESS] Sample from UG burning in: 30 / 300\n",
      "[PROGRESS] Sample from UG burning in: 31 / 300\n",
      "[PROGRESS] Sample from UG burning in: 32 / 300\n",
      "[PROGRESS] Sample from UG burning in: 33 / 300\n",
      "[PROGRESS] Sample from UG burning in: 34 / 300\n",
      "[PROGRESS] Sample from UG burning in: 35 / 300\n",
      "[PROGRESS] Sample from UG burning in: 36 / 300\n",
      "[PROGRESS] Sample from UG burning in: 37 / 300\n",
      "[PROGRESS] Sample from UG burning in: 38 / 300\n",
      "[PROGRESS] Sample from UG burning in: 39 / 300\n",
      "[PROGRESS] Sample from UG burning in: 40 / 300\n",
      "[PROGRESS] Sample from UG burning in: 41 / 300\n",
      "[PROGRESS] Sample from UG burning in: 42 / 300\n",
      "[PROGRESS] Sample from UG burning in: 43 / 300\n",
      "[PROGRESS] Sample from UG burning in: 44 / 300\n",
      "[PROGRESS] Sample from UG burning in: 45 / 300\n",
      "[PROGRESS] Sample from UG burning in: 46 / 300\n",
      "[PROGRESS] Sample from UG burning in: 47 / 300\n",
      "[PROGRESS] Sample from UG burning in: 48 / 300\n",
      "[PROGRESS] Sample from UG burning in: 49 / 300\n",
      "[PROGRESS] Sample from UG burning in: 50 / 300\n",
      "[PROGRESS] Sample from UG burning in: 51 / 300\n",
      "[PROGRESS] Sample from UG burning in: 52 / 300\n",
      "[PROGRESS] Sample from UG burning in: 53 / 300\n",
      "[PROGRESS] Sample from UG burning in: 54 / 300\n",
      "[PROGRESS] Sample from UG burning in: 55 / 300\n",
      "[PROGRESS] Sample from UG burning in: 56 / 300\n",
      "[PROGRESS] Sample from UG burning in: 57 / 300\n",
      "[PROGRESS] Sample from UG burning in: 58 / 300\n",
      "[PROGRESS] Sample from UG burning in: 59 / 300\n",
      "[PROGRESS] Sample from UG burning in: 60 / 300\n",
      "[PROGRESS] Sample from UG burning in: 61 / 300\n",
      "[PROGRESS] Sample from UG burning in: 62 / 300\n",
      "[PROGRESS] Sample from UG burning in: 63 / 300\n",
      "[PROGRESS] Sample from UG burning in: 64 / 300\n",
      "[PROGRESS] Sample from UG burning in: 65 / 300\n",
      "[PROGRESS] Sample from UG burning in: 66 / 300\n",
      "[PROGRESS] Sample from UG burning in: 67 / 300\n",
      "[PROGRESS] Sample from UG burning in: 68 / 300\n",
      "[PROGRESS] Sample from UG burning in: 69 / 300\n",
      "[PROGRESS] Sample from UG burning in: 70 / 300\n",
      "[PROGRESS] Sample from UG burning in: 71 / 300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROGRESS] Sample from UG burning in: 72 / 300\n",
      "[PROGRESS] Sample from UG burning in: 73 / 300\n",
      "[PROGRESS] Sample from UG burning in: 74 / 300\n",
      "[PROGRESS] Sample from UG burning in: 75 / 300\n",
      "[PROGRESS] Sample from UG burning in: 76 / 300\n",
      "[PROGRESS] Sample from UG burning in: 77 / 300\n",
      "[PROGRESS] Sample from UG burning in: 78 / 300\n",
      "[PROGRESS] Sample from UG burning in: 79 / 300\n",
      "[PROGRESS] Sample from UG burning in: 80 / 300\n",
      "[PROGRESS] Sample from UG burning in: 81 / 300\n",
      "[PROGRESS] Sample from UG burning in: 82 / 300\n",
      "[PROGRESS] Sample from UG burning in: 83 / 300\n",
      "[PROGRESS] Sample from UG burning in: 84 / 300\n",
      "[PROGRESS] Sample from UG burning in: 85 / 300\n",
      "[PROGRESS] Sample from UG burning in: 86 / 300\n",
      "[PROGRESS] Sample from UG burning in: 87 / 300\n",
      "[PROGRESS] Sample from UG burning in: 88 / 300\n",
      "[PROGRESS] Sample from UG burning in: 89 / 300\n",
      "[PROGRESS] Sample from UG burning in: 90 / 300\n",
      "[PROGRESS] Sample from UG burning in: 91 / 300\n",
      "[PROGRESS] Sample from UG burning in: 92 / 300\n",
      "[PROGRESS] Sample from UG burning in: 93 / 300\n",
      "[PROGRESS] Sample from UG burning in: 94 / 300\n",
      "[PROGRESS] Sample from UG burning in: 95 / 300\n",
      "[PROGRESS] Sample from UG burning in: 96 / 300\n",
      "[PROGRESS] Sample from UG burning in: 97 / 300\n",
      "[PROGRESS] Sample from UG burning in: 98 / 300\n",
      "[PROGRESS] Sample from UG burning in: 99 / 300\n",
      "[PROGRESS] Sample from UG burning in: 100 / 300\n",
      "[PROGRESS] Sample from UG burning in: 101 / 300\n",
      "[PROGRESS] Sample from UG burning in: 102 / 300\n",
      "[PROGRESS] Sample from UG burning in: 103 / 300\n",
      "[PROGRESS] Sample from UG burning in: 104 / 300\n",
      "[PROGRESS] Sample from UG burning in: 105 / 300\n",
      "[PROGRESS] Sample from UG burning in: 106 / 300\n",
      "[PROGRESS] Sample from UG burning in: 107 / 300\n",
      "[PROGRESS] Sample from UG burning in: 108 / 300\n",
      "[PROGRESS] Sample from UG burning in: 109 / 300\n",
      "[PROGRESS] Sample from UG burning in: 110 / 300\n",
      "[PROGRESS] Sample from UG burning in: 111 / 300\n",
      "[PROGRESS] Sample from UG burning in: 112 / 300\n",
      "[PROGRESS] Sample from UG burning in: 113 / 300\n",
      "[PROGRESS] Sample from UG burning in: 114 / 300\n",
      "[PROGRESS] Sample from UG burning in: 115 / 300\n",
      "[PROGRESS] Sample from UG burning in: 116 / 300\n",
      "[PROGRESS] Sample from UG burning in: 117 / 300\n",
      "[PROGRESS] Sample from UG burning in: 118 / 300\n",
      "[PROGRESS] Sample from UG burning in: 119 / 300\n",
      "[PROGRESS] Sample from UG burning in: 120 / 300\n",
      "[PROGRESS] Sample from UG burning in: 121 / 300\n",
      "[PROGRESS] Sample from UG burning in: 122 / 300\n",
      "[PROGRESS] Sample from UG burning in: 123 / 300\n",
      "[PROGRESS] Sample from UG burning in: 124 / 300\n",
      "[PROGRESS] Sample from UG burning in: 125 / 300\n",
      "[PROGRESS] Sample from UG burning in: 126 / 300\n",
      "[PROGRESS] Sample from UG burning in: 127 / 300\n",
      "[PROGRESS] Sample from UG burning in: 128 / 300\n",
      "[PROGRESS] Sample from UG burning in: 129 / 300\n",
      "[PROGRESS] Sample from UG burning in: 130 / 300\n",
      "[PROGRESS] Sample from UG burning in: 131 / 300\n",
      "[PROGRESS] Sample from UG burning in: 132 / 300\n",
      "[PROGRESS] Sample from UG burning in: 133 / 300\n",
      "[PROGRESS] Sample from UG burning in: 134 / 300\n",
      "[PROGRESS] Sample from UG burning in: 135 / 300\n",
      "[PROGRESS] Sample from UG burning in: 136 / 300\n",
      "[PROGRESS] Sample from UG burning in: 137 / 300\n",
      "[PROGRESS] Sample from UG burning in: 138 / 300\n",
      "[PROGRESS] Sample from UG burning in: 139 / 300\n",
      "[PROGRESS] Sample from UG burning in: 140 / 300\n",
      "[PROGRESS] Sample from UG burning in: 141 / 300\n",
      "[PROGRESS] Sample from UG burning in: 142 / 300\n",
      "[PROGRESS] Sample from UG burning in: 143 / 300\n",
      "[PROGRESS] Sample from UG burning in: 144 / 300\n",
      "[PROGRESS] Sample from UG burning in: 145 / 300\n",
      "[PROGRESS] Sample from UG burning in: 146 / 300\n",
      "[PROGRESS] Sample from UG burning in: 147 / 300\n",
      "[PROGRESS] Sample from UG burning in: 148 / 300\n",
      "[PROGRESS] Sample from UG burning in: 149 / 300\n",
      "[PROGRESS] Sample from UG burning in: 150 / 300\n",
      "[PROGRESS] Sample from UG burning in: 151 / 300\n",
      "[PROGRESS] Sample from UG burning in: 152 / 300\n",
      "[PROGRESS] Sample from UG burning in: 153 / 300\n",
      "[PROGRESS] Sample from UG burning in: 154 / 300\n",
      "[PROGRESS] Sample from UG burning in: 155 / 300\n",
      "[PROGRESS] Sample from UG burning in: 156 / 300\n",
      "[PROGRESS] Sample from UG burning in: 157 / 300\n",
      "[PROGRESS] Sample from UG burning in: 158 / 300\n",
      "[PROGRESS] Sample from UG burning in: 159 / 300\n",
      "[PROGRESS] Sample from UG burning in: 160 / 300\n",
      "[PROGRESS] Sample from UG burning in: 161 / 300\n",
      "[PROGRESS] Sample from UG burning in: 162 / 300\n",
      "[PROGRESS] Sample from UG burning in: 163 / 300\n",
      "[PROGRESS] Sample from UG burning in: 164 / 300\n",
      "[PROGRESS] Sample from UG burning in: 165 / 300\n",
      "[PROGRESS] Sample from UG burning in: 166 / 300\n",
      "[PROGRESS] Sample from UG burning in: 167 / 300\n",
      "[PROGRESS] Sample from UG burning in: 168 / 300\n",
      "[PROGRESS] Sample from UG burning in: 169 / 300\n",
      "[PROGRESS] Sample from UG burning in: 170 / 300\n",
      "[PROGRESS] Sample from UG burning in: 171 / 300\n",
      "[PROGRESS] Sample from UG burning in: 172 / 300\n",
      "[PROGRESS] Sample from UG burning in: 173 / 300\n",
      "[PROGRESS] Sample from UG burning in: 174 / 300\n",
      "[PROGRESS] Sample from UG burning in: 175 / 300\n",
      "[PROGRESS] Sample from UG burning in: 176 / 300\n",
      "[PROGRESS] Sample from UG burning in: 177 / 300\n",
      "[PROGRESS] Sample from UG burning in: 178 / 300\n",
      "[PROGRESS] Sample from UG burning in: 179 / 300\n",
      "[PROGRESS] Sample from UG burning in: 180 / 300\n",
      "[PROGRESS] Sample from UG burning in: 181 / 300\n",
      "[PROGRESS] Sample from UG burning in: 182 / 300\n",
      "[PROGRESS] Sample from UG burning in: 183 / 300\n",
      "[PROGRESS] Sample from UG burning in: 184 / 300\n",
      "[PROGRESS] Sample from UG burning in: 185 / 300\n",
      "[PROGRESS] Sample from UG burning in: 186 / 300\n",
      "[PROGRESS] Sample from UG burning in: 187 / 300\n",
      "[PROGRESS] Sample from UG burning in: 188 / 300\n",
      "[PROGRESS] Sample from UG burning in: 189 / 300\n",
      "[PROGRESS] Sample from UG burning in: 190 / 300\n",
      "[PROGRESS] Sample from UG burning in: 191 / 300\n",
      "[PROGRESS] Sample from UG burning in: 192 / 300\n",
      "[PROGRESS] Sample from UG burning in: 193 / 300\n",
      "[PROGRESS] Sample from UG burning in: 194 / 300\n",
      "[PROGRESS] Sample from UG burning in: 195 / 300\n",
      "[PROGRESS] Sample from UG burning in: 196 / 300\n",
      "[PROGRESS] Sample from UG burning in: 197 / 300\n",
      "[PROGRESS] Sample from UG burning in: 198 / 300\n",
      "[PROGRESS] Sample from UG burning in: 199 / 300\n",
      "[PROGRESS] Sample from UG burning in: 200 / 300\n",
      "[PROGRESS] Sample from UG burning in: 201 / 300\n",
      "[PROGRESS] Sample from UG burning in: 202 / 300\n",
      "[PROGRESS] Sample from UG burning in: 203 / 300\n",
      "[PROGRESS] Sample from UG burning in: 204 / 300\n",
      "[PROGRESS] Sample from UG burning in: 205 / 300\n",
      "[PROGRESS] Sample from UG burning in: 206 / 300\n",
      "[PROGRESS] Sample from UG burning in: 207 / 300\n",
      "[PROGRESS] Sample from UG burning in: 208 / 300\n",
      "[PROGRESS] Sample from UG burning in: 209 / 300\n",
      "[PROGRESS] Sample from UG burning in: 210 / 300\n",
      "[PROGRESS] Sample from UG burning in: 211 / 300\n",
      "[PROGRESS] Sample from UG burning in: 212 / 300\n",
      "[PROGRESS] Sample from UG burning in: 213 / 300\n",
      "[PROGRESS] Sample from UG burning in: 214 / 300\n",
      "[PROGRESS] Sample from UG burning in: 215 / 300\n",
      "[PROGRESS] Sample from UG burning in: 216 / 300\n",
      "[PROGRESS] Sample from UG burning in: 217 / 300\n",
      "[PROGRESS] Sample from UG burning in: 218 / 300\n",
      "[PROGRESS] Sample from UG burning in: 219 / 300\n",
      "[PROGRESS] Sample from UG burning in: 220 / 300\n",
      "[PROGRESS] Sample from UG burning in: 221 / 300\n",
      "[PROGRESS] Sample from UG burning in: 222 / 300\n",
      "[PROGRESS] Sample from UG burning in: 223 / 300\n",
      "[PROGRESS] Sample from UG burning in: 224 / 300\n",
      "[PROGRESS] Sample from UG burning in: 225 / 300\n",
      "[PROGRESS] Sample from UG burning in: 226 / 300\n",
      "[PROGRESS] Sample from UG burning in: 227 / 300\n",
      "[PROGRESS] Sample from UG burning in: 228 / 300\n",
      "[PROGRESS] Sample from UG burning in: 229 / 300\n",
      "[PROGRESS] Sample from UG burning in: 230 / 300\n",
      "[PROGRESS] Sample from UG burning in: 231 / 300\n",
      "[PROGRESS] Sample from UG burning in: 232 / 300\n",
      "[PROGRESS] Sample from UG burning in: 233 / 300\n",
      "[PROGRESS] Sample from UG burning in: 234 / 300\n",
      "[PROGRESS] Sample from UG burning in: 235 / 300\n",
      "[PROGRESS] Sample from UG burning in: 236 / 300\n",
      "[PROGRESS] Sample from UG burning in: 237 / 300\n",
      "[PROGRESS] Sample from UG burning in: 238 / 300\n",
      "[PROGRESS] Sample from UG burning in: 239 / 300\n",
      "[PROGRESS] Sample from UG burning in: 240 / 300\n",
      "[PROGRESS] Sample from UG burning in: 241 / 300\n",
      "[PROGRESS] Sample from UG burning in: 242 / 300\n",
      "[PROGRESS] Sample from UG burning in: 243 / 300\n",
      "[PROGRESS] Sample from UG burning in: 244 / 300\n",
      "[PROGRESS] Sample from UG burning in: 245 / 300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROGRESS] Sample from UG burning in: 246 / 300\n",
      "[PROGRESS] Sample from UG burning in: 247 / 300\n",
      "[PROGRESS] Sample from UG burning in: 248 / 300\n",
      "[PROGRESS] Sample from UG burning in: 249 / 300\n",
      "[PROGRESS] Sample from UG burning in: 250 / 300\n",
      "[PROGRESS] Sample from UG burning in: 251 / 300\n",
      "[PROGRESS] Sample from UG burning in: 252 / 300\n",
      "[PROGRESS] Sample from UG burning in: 253 / 300\n",
      "[PROGRESS] Sample from UG burning in: 254 / 300\n",
      "[PROGRESS] Sample from UG burning in: 255 / 300\n",
      "[PROGRESS] Sample from UG burning in: 256 / 300\n",
      "[PROGRESS] Sample from UG burning in: 257 / 300\n",
      "[PROGRESS] Sample from UG burning in: 258 / 300\n",
      "[PROGRESS] Sample from UG burning in: 259 / 300\n",
      "[PROGRESS] Sample from UG burning in: 260 / 300\n",
      "[PROGRESS] Sample from UG burning in: 261 / 300\n",
      "[PROGRESS] Sample from UG burning in: 262 / 300\n",
      "[PROGRESS] Sample from UG burning in: 263 / 300\n",
      "[PROGRESS] Sample from UG burning in: 264 / 300\n",
      "[PROGRESS] Sample from UG burning in: 265 / 300\n",
      "[PROGRESS] Sample from UG burning in: 266 / 300\n",
      "[PROGRESS] Sample from UG burning in: 267 / 300\n",
      "[PROGRESS] Sample from UG burning in: 268 / 300\n",
      "[PROGRESS] Sample from UG burning in: 269 / 300\n",
      "[PROGRESS] Sample from UG burning in: 270 / 300\n",
      "[PROGRESS] Sample from UG burning in: 271 / 300\n",
      "[PROGRESS] Sample from UG burning in: 272 / 300\n",
      "[PROGRESS] Sample from UG burning in: 273 / 300\n",
      "[PROGRESS] Sample from UG burning in: 274 / 300\n",
      "[PROGRESS] Sample from UG burning in: 275 / 300\n",
      "[PROGRESS] Sample from UG burning in: 276 / 300\n",
      "[PROGRESS] Sample from UG burning in: 277 / 300\n",
      "[PROGRESS] Sample from UG burning in: 278 / 300\n",
      "[PROGRESS] Sample from UG burning in: 279 / 300\n",
      "[PROGRESS] Sample from UG burning in: 280 / 300\n",
      "[PROGRESS] Sample from UG burning in: 281 / 300\n",
      "[PROGRESS] Sample from UG burning in: 282 / 300\n",
      "[PROGRESS] Sample from UG burning in: 283 / 300\n",
      "[PROGRESS] Sample from UG burning in: 284 / 300\n",
      "[PROGRESS] Sample from UG burning in: 285 / 300\n",
      "[PROGRESS] Sample from UG burning in: 286 / 300\n",
      "[PROGRESS] Sample from UG burning in: 287 / 300\n",
      "[PROGRESS] Sample from UG burning in: 288 / 300\n",
      "[PROGRESS] Sample from UG burning in: 289 / 300\n",
      "[PROGRESS] Sample from UG burning in: 290 / 300\n",
      "[PROGRESS] Sample from UG burning in: 291 / 300\n",
      "[PROGRESS] Sample from UG burning in: 292 / 300\n",
      "[PROGRESS] Sample from UG burning in: 293 / 300\n",
      "[PROGRESS] Sample from UG burning in: 294 / 300\n",
      "[PROGRESS] Sample from UG burning in: 295 / 300\n",
      "[PROGRESS] Sample from UG burning in: 296 / 300\n",
      "[PROGRESS] Sample from UG burning in: 297 / 300\n",
      "[PROGRESS] Sample from UG burning in: 298 / 300\n",
      "[PROGRESS] Sample from UG burning in: 299 / 300\n",
      "[PROGRESS] Sample from UG burning in: 0 / 300\n",
      "[PROGRESS] Sample from UG burning in: 1 / 300\n",
      "[PROGRESS] Sample from UG burning in: 2 / 300\n",
      "[PROGRESS] Sample from UG burning in: 3 / 300\n",
      "[PROGRESS] Sample from UG burning in: 4 / 300\n",
      "[PROGRESS] Sample from UG burning in: 5 / 300\n",
      "[PROGRESS] Sample from UG burning in: 6 / 300\n",
      "[PROGRESS] Sample from UG burning in: 7 / 300\n",
      "[PROGRESS] Sample from UG burning in: 8 / 300\n",
      "[PROGRESS] Sample from UG burning in: 9 / 300\n",
      "[PROGRESS] Sample from UG burning in: 10 / 300\n",
      "[PROGRESS] Sample from UG burning in: 11 / 300\n",
      "[PROGRESS] Sample from UG burning in: 12 / 300\n",
      "[PROGRESS] Sample from UG burning in: 13 / 300\n",
      "[PROGRESS] Sample from UG burning in: 14 / 300\n",
      "[PROGRESS] Sample from UG burning in: 15 / 300\n",
      "[PROGRESS] Sample from UG burning in: 16 / 300\n",
      "[PROGRESS] Sample from UG burning in: 17 / 300\n",
      "[PROGRESS] Sample from UG burning in: 18 / 300\n",
      "[PROGRESS] Sample from UG burning in: 19 / 300\n",
      "[PROGRESS] Sample from UG burning in: 20 / 300\n",
      "[PROGRESS] Sample from UG burning in: 21 / 300\n",
      "[PROGRESS] Sample from UG burning in: 22 / 300\n",
      "[PROGRESS] Sample from UG burning in: 23 / 300\n",
      "[PROGRESS] Sample from UG burning in: 24 / 300\n",
      "[PROGRESS] Sample from UG burning in: 25 / 300\n",
      "[PROGRESS] Sample from UG burning in: 26 / 300\n",
      "[PROGRESS] Sample from UG burning in: 27 / 300\n",
      "[PROGRESS] Sample from UG burning in: 28 / 300\n",
      "[PROGRESS] Sample from UG burning in: 29 / 300\n",
      "[PROGRESS] Sample from UG burning in: 30 / 300\n",
      "[PROGRESS] Sample from UG burning in: 31 / 300\n",
      "[PROGRESS] Sample from UG burning in: 32 / 300\n",
      "[PROGRESS] Sample from UG burning in: 33 / 300\n",
      "[PROGRESS] Sample from UG burning in: 34 / 300\n",
      "[PROGRESS] Sample from UG burning in: 35 / 300\n",
      "[PROGRESS] Sample from UG burning in: 36 / 300\n",
      "[PROGRESS] Sample from UG burning in: 37 / 300\n",
      "[PROGRESS] Sample from UG burning in: 38 / 300\n",
      "[PROGRESS] Sample from UG burning in: 39 / 300\n",
      "[PROGRESS] Sample from UG burning in: 40 / 300\n",
      "[PROGRESS] Sample from UG burning in: 41 / 300\n",
      "[PROGRESS] Sample from UG burning in: 42 / 300\n",
      "[PROGRESS] Sample from UG burning in: 43 / 300\n",
      "[PROGRESS] Sample from UG burning in: 44 / 300\n",
      "[PROGRESS] Sample from UG burning in: 45 / 300\n",
      "[PROGRESS] Sample from UG burning in: 46 / 300\n",
      "[PROGRESS] Sample from UG burning in: 47 / 300\n",
      "[PROGRESS] Sample from UG burning in: 48 / 300\n",
      "[PROGRESS] Sample from UG burning in: 49 / 300\n",
      "[PROGRESS] Sample from UG burning in: 50 / 300\n",
      "[PROGRESS] Sample from UG burning in: 51 / 300\n",
      "[PROGRESS] Sample from UG burning in: 52 / 300\n",
      "[PROGRESS] Sample from UG burning in: 53 / 300\n",
      "[PROGRESS] Sample from UG burning in: 54 / 300\n",
      "[PROGRESS] Sample from UG burning in: 55 / 300\n",
      "[PROGRESS] Sample from UG burning in: 56 / 300\n",
      "[PROGRESS] Sample from UG burning in: 57 / 300\n",
      "[PROGRESS] Sample from UG burning in: 58 / 300\n",
      "[PROGRESS] Sample from UG burning in: 59 / 300\n",
      "[PROGRESS] Sample from UG burning in: 60 / 300\n",
      "[PROGRESS] Sample from UG burning in: 61 / 300\n",
      "[PROGRESS] Sample from UG burning in: 62 / 300\n",
      "[PROGRESS] Sample from UG burning in: 63 / 300\n",
      "[PROGRESS] Sample from UG burning in: 64 / 300\n",
      "[PROGRESS] Sample from UG burning in: 65 / 300\n",
      "[PROGRESS] Sample from UG burning in: 66 / 300\n",
      "[PROGRESS] Sample from UG burning in: 67 / 300\n",
      "[PROGRESS] Sample from UG burning in: 68 / 300\n",
      "[PROGRESS] Sample from UG burning in: 69 / 300\n",
      "[PROGRESS] Sample from UG burning in: 70 / 300\n",
      "[PROGRESS] Sample from UG burning in: 71 / 300\n",
      "[PROGRESS] Sample from UG burning in: 72 / 300\n",
      "[PROGRESS] Sample from UG burning in: 73 / 300\n",
      "[PROGRESS] Sample from UG burning in: 74 / 300\n",
      "[PROGRESS] Sample from UG burning in: 75 / 300\n",
      "[PROGRESS] Sample from UG burning in: 76 / 300\n",
      "[PROGRESS] Sample from UG burning in: 77 / 300\n",
      "[PROGRESS] Sample from UG burning in: 78 / 300\n",
      "[PROGRESS] Sample from UG burning in: 79 / 300\n",
      "[PROGRESS] Sample from UG burning in: 80 / 300\n",
      "[PROGRESS] Sample from UG burning in: 81 / 300\n",
      "[PROGRESS] Sample from UG burning in: 82 / 300\n",
      "[PROGRESS] Sample from UG burning in: 83 / 300\n",
      "[PROGRESS] Sample from UG burning in: 84 / 300\n",
      "[PROGRESS] Sample from UG burning in: 85 / 300\n",
      "[PROGRESS] Sample from UG burning in: 86 / 300\n",
      "[PROGRESS] Sample from UG burning in: 87 / 300\n",
      "[PROGRESS] Sample from UG burning in: 88 / 300\n",
      "[PROGRESS] Sample from UG burning in: 89 / 300\n",
      "[PROGRESS] Sample from UG burning in: 90 / 300\n",
      "[PROGRESS] Sample from UG burning in: 91 / 300\n",
      "[PROGRESS] Sample from UG burning in: 92 / 300\n",
      "[PROGRESS] Sample from UG burning in: 93 / 300\n",
      "[PROGRESS] Sample from UG burning in: 94 / 300\n",
      "[PROGRESS] Sample from UG burning in: 95 / 300\n",
      "[PROGRESS] Sample from UG burning in: 96 / 300\n",
      "[PROGRESS] Sample from UG burning in: 97 / 300\n",
      "[PROGRESS] Sample from UG burning in: 98 / 300\n",
      "[PROGRESS] Sample from UG burning in: 99 / 300\n",
      "[PROGRESS] Sample from UG burning in: 100 / 300\n",
      "[PROGRESS] Sample from UG burning in: 101 / 300\n",
      "[PROGRESS] Sample from UG burning in: 102 / 300\n",
      "[PROGRESS] Sample from UG burning in: 103 / 300\n",
      "[PROGRESS] Sample from UG burning in: 104 / 300\n",
      "[PROGRESS] Sample from UG burning in: 105 / 300\n",
      "[PROGRESS] Sample from UG burning in: 106 / 300\n",
      "[PROGRESS] Sample from UG burning in: 107 / 300\n",
      "[PROGRESS] Sample from UG burning in: 108 / 300\n",
      "[PROGRESS] Sample from UG burning in: 109 / 300\n",
      "[PROGRESS] Sample from UG burning in: 110 / 300\n",
      "[PROGRESS] Sample from UG burning in: 111 / 300\n",
      "[PROGRESS] Sample from UG burning in: 112 / 300\n",
      "[PROGRESS] Sample from UG burning in: 113 / 300\n",
      "[PROGRESS] Sample from UG burning in: 114 / 300\n",
      "[PROGRESS] Sample from UG burning in: 115 / 300\n",
      "[PROGRESS] Sample from UG burning in: 116 / 300\n",
      "[PROGRESS] Sample from UG burning in: 117 / 300\n",
      "[PROGRESS] Sample from UG burning in: 118 / 300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROGRESS] Sample from UG burning in: 119 / 300\n",
      "[PROGRESS] Sample from UG burning in: 120 / 300\n",
      "[PROGRESS] Sample from UG burning in: 121 / 300\n",
      "[PROGRESS] Sample from UG burning in: 122 / 300\n",
      "[PROGRESS] Sample from UG burning in: 123 / 300\n",
      "[PROGRESS] Sample from UG burning in: 124 / 300\n",
      "[PROGRESS] Sample from UG burning in: 125 / 300\n",
      "[PROGRESS] Sample from UG burning in: 126 / 300\n",
      "[PROGRESS] Sample from UG burning in: 127 / 300\n",
      "[PROGRESS] Sample from UG burning in: 128 / 300\n",
      "[PROGRESS] Sample from UG burning in: 129 / 300\n",
      "[PROGRESS] Sample from UG burning in: 130 / 300\n",
      "[PROGRESS] Sample from UG burning in: 131 / 300\n",
      "[PROGRESS] Sample from UG burning in: 132 / 300\n",
      "[PROGRESS] Sample from UG burning in: 133 / 300\n",
      "[PROGRESS] Sample from UG burning in: 134 / 300\n",
      "[PROGRESS] Sample from UG burning in: 135 / 300\n",
      "[PROGRESS] Sample from UG burning in: 136 / 300\n",
      "[PROGRESS] Sample from UG burning in: 137 / 300\n",
      "[PROGRESS] Sample from UG burning in: 138 / 300\n",
      "[PROGRESS] Sample from UG burning in: 139 / 300\n",
      "[PROGRESS] Sample from UG burning in: 140 / 300\n",
      "[PROGRESS] Sample from UG burning in: 141 / 300\n",
      "[PROGRESS] Sample from UG burning in: 142 / 300\n",
      "[PROGRESS] Sample from UG burning in: 143 / 300\n",
      "[PROGRESS] Sample from UG burning in: 144 / 300\n",
      "[PROGRESS] Sample from UG burning in: 145 / 300\n",
      "[PROGRESS] Sample from UG burning in: 146 / 300\n",
      "[PROGRESS] Sample from UG burning in: 147 / 300\n",
      "[PROGRESS] Sample from UG burning in: 148 / 300\n",
      "[PROGRESS] Sample from UG burning in: 149 / 300\n",
      "[PROGRESS] Sample from UG burning in: 150 / 300\n",
      "[PROGRESS] Sample from UG burning in: 151 / 300\n",
      "[PROGRESS] Sample from UG burning in: 152 / 300\n",
      "[PROGRESS] Sample from UG burning in: 153 / 300\n",
      "[PROGRESS] Sample from UG burning in: 154 / 300\n",
      "[PROGRESS] Sample from UG burning in: 155 / 300\n",
      "[PROGRESS] Sample from UG burning in: 156 / 300\n",
      "[PROGRESS] Sample from UG burning in: 157 / 300\n",
      "[PROGRESS] Sample from UG burning in: 158 / 300\n",
      "[PROGRESS] Sample from UG burning in: 159 / 300\n",
      "[PROGRESS] Sample from UG burning in: 160 / 300\n",
      "[PROGRESS] Sample from UG burning in: 161 / 300\n",
      "[PROGRESS] Sample from UG burning in: 162 / 300\n",
      "[PROGRESS] Sample from UG burning in: 163 / 300\n",
      "[PROGRESS] Sample from UG burning in: 164 / 300\n",
      "[PROGRESS] Sample from UG burning in: 165 / 300\n",
      "[PROGRESS] Sample from UG burning in: 166 / 300\n",
      "[PROGRESS] Sample from UG burning in: 167 / 300\n",
      "[PROGRESS] Sample from UG burning in: 168 / 300\n",
      "[PROGRESS] Sample from UG burning in: 169 / 300\n",
      "[PROGRESS] Sample from UG burning in: 170 / 300\n",
      "[PROGRESS] Sample from UG burning in: 171 / 300\n",
      "[PROGRESS] Sample from UG burning in: 172 / 300\n",
      "[PROGRESS] Sample from UG burning in: 173 / 300\n",
      "[PROGRESS] Sample from UG burning in: 174 / 300\n",
      "[PROGRESS] Sample from UG burning in: 175 / 300\n",
      "[PROGRESS] Sample from UG burning in: 176 / 300\n",
      "[PROGRESS] Sample from UG burning in: 177 / 300\n",
      "[PROGRESS] Sample from UG burning in: 178 / 300\n",
      "[PROGRESS] Sample from UG burning in: 179 / 300\n",
      "[PROGRESS] Sample from UG burning in: 180 / 300\n",
      "[PROGRESS] Sample from UG burning in: 181 / 300\n",
      "[PROGRESS] Sample from UG burning in: 182 / 300\n",
      "[PROGRESS] Sample from UG burning in: 183 / 300\n",
      "[PROGRESS] Sample from UG burning in: 184 / 300\n",
      "[PROGRESS] Sample from UG burning in: 185 / 300\n",
      "[PROGRESS] Sample from UG burning in: 186 / 300\n",
      "[PROGRESS] Sample from UG burning in: 187 / 300\n",
      "[PROGRESS] Sample from UG burning in: 188 / 300\n",
      "[PROGRESS] Sample from UG burning in: 189 / 300\n",
      "[PROGRESS] Sample from UG burning in: 190 / 300\n",
      "[PROGRESS] Sample from UG burning in: 191 / 300\n",
      "[PROGRESS] Sample from UG burning in: 192 / 300\n",
      "[PROGRESS] Sample from UG burning in: 193 / 300\n",
      "[PROGRESS] Sample from UG burning in: 194 / 300\n",
      "[PROGRESS] Sample from UG burning in: 195 / 300\n",
      "[PROGRESS] Sample from UG burning in: 196 / 300\n",
      "[PROGRESS] Sample from UG burning in: 197 / 300\n",
      "[PROGRESS] Sample from UG burning in: 198 / 300\n",
      "[PROGRESS] Sample from UG burning in: 199 / 300\n",
      "[PROGRESS] Sample from UG burning in: 200 / 300\n",
      "[PROGRESS] Sample from UG burning in: 201 / 300\n",
      "[PROGRESS] Sample from UG burning in: 202 / 300\n",
      "[PROGRESS] Sample from UG burning in: 203 / 300\n",
      "[PROGRESS] Sample from UG burning in: 204 / 300\n",
      "[PROGRESS] Sample from UG burning in: 205 / 300\n",
      "[PROGRESS] Sample from UG burning in: 206 / 300\n",
      "[PROGRESS] Sample from UG burning in: 207 / 300\n",
      "[PROGRESS] Sample from UG burning in: 208 / 300\n",
      "[PROGRESS] Sample from UG burning in: 209 / 300\n",
      "[PROGRESS] Sample from UG burning in: 210 / 300\n",
      "[PROGRESS] Sample from UG burning in: 211 / 300\n",
      "[PROGRESS] Sample from UG burning in: 212 / 300\n",
      "[PROGRESS] Sample from UG burning in: 213 / 300\n",
      "[PROGRESS] Sample from UG burning in: 214 / 300\n",
      "[PROGRESS] Sample from UG burning in: 215 / 300\n",
      "[PROGRESS] Sample from UG burning in: 216 / 300\n",
      "[PROGRESS] Sample from UG burning in: 217 / 300\n",
      "[PROGRESS] Sample from UG burning in: 218 / 300\n",
      "[PROGRESS] Sample from UG burning in: 219 / 300\n",
      "[PROGRESS] Sample from UG burning in: 220 / 300\n",
      "[PROGRESS] Sample from UG burning in: 221 / 300\n",
      "[PROGRESS] Sample from UG burning in: 222 / 300\n",
      "[PROGRESS] Sample from UG burning in: 223 / 300\n",
      "[PROGRESS] Sample from UG burning in: 224 / 300\n",
      "[PROGRESS] Sample from UG burning in: 225 / 300\n",
      "[PROGRESS] Sample from UG burning in: 226 / 300\n",
      "[PROGRESS] Sample from UG burning in: 227 / 300\n",
      "[PROGRESS] Sample from UG burning in: 228 / 300\n",
      "[PROGRESS] Sample from UG burning in: 229 / 300\n",
      "[PROGRESS] Sample from UG burning in: 230 / 300\n",
      "[PROGRESS] Sample from UG burning in: 231 / 300\n",
      "[PROGRESS] Sample from UG burning in: 232 / 300\n",
      "[PROGRESS] Sample from UG burning in: 233 / 300\n",
      "[PROGRESS] Sample from UG burning in: 234 / 300\n",
      "[PROGRESS] Sample from UG burning in: 235 / 300\n",
      "[PROGRESS] Sample from UG burning in: 236 / 300\n",
      "[PROGRESS] Sample from UG burning in: 237 / 300\n",
      "[PROGRESS] Sample from UG burning in: 238 / 300\n",
      "[PROGRESS] Sample from UG burning in: 239 / 300\n",
      "[PROGRESS] Sample from UG burning in: 240 / 300\n",
      "[PROGRESS] Sample from UG burning in: 241 / 300\n",
      "[PROGRESS] Sample from UG burning in: 242 / 300\n",
      "[PROGRESS] Sample from UG burning in: 243 / 300\n",
      "[PROGRESS] Sample from UG burning in: 244 / 300\n",
      "[PROGRESS] Sample from UG burning in: 245 / 300\n",
      "[PROGRESS] Sample from UG burning in: 246 / 300\n",
      "[PROGRESS] Sample from UG burning in: 247 / 300\n",
      "[PROGRESS] Sample from UG burning in: 248 / 300\n",
      "[PROGRESS] Sample from UG burning in: 249 / 300\n",
      "[PROGRESS] Sample from UG burning in: 250 / 300\n",
      "[PROGRESS] Sample from UG burning in: 251 / 300\n",
      "[PROGRESS] Sample from UG burning in: 252 / 300\n",
      "[PROGRESS] Sample from UG burning in: 253 / 300\n",
      "[PROGRESS] Sample from UG burning in: 254 / 300\n",
      "[PROGRESS] Sample from UG burning in: 255 / 300\n",
      "[PROGRESS] Sample from UG burning in: 256 / 300\n",
      "[PROGRESS] Sample from UG burning in: 257 / 300\n",
      "[PROGRESS] Sample from UG burning in: 258 / 300\n",
      "[PROGRESS] Sample from UG burning in: 259 / 300\n",
      "[PROGRESS] Sample from UG burning in: 260 / 300\n",
      "[PROGRESS] Sample from UG burning in: 261 / 300\n",
      "[PROGRESS] Sample from UG burning in: 262 / 300\n",
      "[PROGRESS] Sample from UG burning in: 263 / 300\n",
      "[PROGRESS] Sample from UG burning in: 264 / 300\n",
      "[PROGRESS] Sample from UG burning in: 265 / 300\n",
      "[PROGRESS] Sample from UG burning in: 266 / 300\n",
      "[PROGRESS] Sample from UG burning in: 267 / 300\n",
      "[PROGRESS] Sample from UG burning in: 268 / 300\n",
      "[PROGRESS] Sample from UG burning in: 269 / 300\n",
      "[PROGRESS] Sample from UG burning in: 270 / 300\n",
      "[PROGRESS] Sample from UG burning in: 271 / 300\n",
      "[PROGRESS] Sample from UG burning in: 272 / 300\n",
      "[PROGRESS] Sample from UG burning in: 273 / 300\n",
      "[PROGRESS] Sample from UG burning in: 274 / 300\n",
      "[PROGRESS] Sample from UG burning in: 275 / 300\n",
      "[PROGRESS] Sample from UG burning in: 276 / 300\n",
      "[PROGRESS] Sample from UG burning in: 277 / 300\n",
      "[PROGRESS] Sample from UG burning in: 278 / 300\n",
      "[PROGRESS] Sample from UG burning in: 279 / 300\n",
      "[PROGRESS] Sample from UG burning in: 280 / 300\n",
      "[PROGRESS] Sample from UG burning in: 281 / 300\n",
      "[PROGRESS] Sample from UG burning in: 282 / 300\n",
      "[PROGRESS] Sample from UG burning in: 283 / 300\n",
      "[PROGRESS] Sample from UG burning in: 284 / 300\n",
      "[PROGRESS] Sample from UG burning in: 285 / 300\n",
      "[PROGRESS] Sample from UG burning in: 286 / 300\n",
      "[PROGRESS] Sample from UG burning in: 287 / 300\n",
      "[PROGRESS] Sample from UG burning in: 288 / 300\n",
      "[PROGRESS] Sample from UG burning in: 289 / 300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROGRESS] Sample from UG burning in: 290 / 300\n",
      "[PROGRESS] Sample from UG burning in: 291 / 300\n",
      "[PROGRESS] Sample from UG burning in: 292 / 300\n",
      "[PROGRESS] Sample from UG burning in: 293 / 300\n",
      "[PROGRESS] Sample from UG burning in: 294 / 300\n",
      "[PROGRESS] Sample from UG burning in: 295 / 300\n",
      "[PROGRESS] Sample from UG burning in: 296 / 300\n",
      "[PROGRESS] Sample from UG burning in: 297 / 300\n",
      "[PROGRESS] Sample from UG burning in: 298 / 300\n",
      "[PROGRESS] Sample from UG burning in: 299 / 300\n"
     ]
    }
   ],
   "source": [
    "BURN_IN = 300\n",
    "VERBOSE = True\n",
    "edge_types = generate_edge_types(\"UUU\")\n",
    "\n",
    "# Sample a single realization from the specified Graphical Model\n",
    "GM_sample = dg.sample_L_A_Y(n_samples=1, network=network, edge_types=edge_types)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "a4591c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_set = maximal_independent_set.maximal_n_apart_independent_set(network, 1)\n",
    "ind_set = pd.DataFrame(list(ind_set), columns=[\"subject\"])\n",
    "est_df = df_for_estimation(network=network, ind_set=ind_set, sample=GM_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "d2d3d66e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "beta_0, beta_1, beta_2, beta_3, beta_4, theta = [0.5]*6\n",
    "initial_params = [beta_0, beta_1, beta_2, beta_3, beta_4, theta]\n",
    "params_Y = optimize_params(nlcl, initial_params, f_Y_i_given_stuff, est_df)\n",
    "\n",
    "beta_0, beta_1 = [0]*2\n",
    "initial_params = [beta_0, beta_1]\n",
    "params_L = optimize_params(nlcl, initial_params, f_L_i_given_stuff, est_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "8af5ca3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.42806528, -0.18069905,  0.22173799, -0.01905073,  0.03608502,\n",
       "        0.03708152])"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "111edc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hat_f_Yi(inputs):\n",
    "    '''\n",
    "    return: proba of yi = 1\n",
    "    '''\n",
    "    y_i = 1\n",
    "    l_i = inputs['L_self']\n",
    "    a_i = inputs['A_self']\n",
    "        \n",
    "    normalizing_weight = 1 #/ len(inputs['Y_neighbors'])\n",
    "        \n",
    "    l_j = inputs['L_neighbors']\n",
    "    a_j = inputs['A_neighbors']\n",
    "    y_j = inputs['Y_neighbors']\n",
    "    \n",
    "    sum_l_j = sum(l_j)\n",
    "    adjusted_sum_l_j = sum_l_j * normalizing_weight\n",
    "\n",
    "    sum_a_j = sum(a_j)\n",
    "    adjusted_sum_a_j = sum_a_j * normalizing_weight\n",
    "\n",
    "    w_ij_y = normalizing_weight\n",
    "    w_ij_l = normalizing_weight\n",
    "        \n",
    "    inputs = {\n",
    "        'y_i': y_i,\n",
    "        'a_i': a_i,\n",
    "        'l_i': l_i,\n",
    "        'l_j_list': l_j,\n",
    "        'y_j_list': y_j,  \n",
    "        'adjusted_sum_l_j': adjusted_sum_l_j,\n",
    "        'adjusted_sum_a_j': adjusted_sum_a_j,\n",
    "        'w_ij_y': w_ij_yw_ij_theta,\n",
    "        'w_ij_l': w_ij_l \n",
    "    }\n",
    "        \n",
    "    return f_Y_i_given_stuff(inputs, params_Y)\n",
    "\n",
    "\n",
    "def hat_f_Li(inputs):\n",
    "    '''\n",
    "    return: proba of yi = 1\n",
    "    \n",
    "    ata_i['l_i']\n",
    "    H_i_output = H_i(l_i=l_i, \n",
    "                     adjusted_sum_l_j=data_i['adjusted_sum_l_j'], \n",
    "                     params=params)\n",
    "    \n",
    "    second_term = 0\n",
    "    for l_j in data_i['l_j_list']:\n",
    "        second_term += l_i * l_j * data_i['w_ij_l']\n",
    "    '''\n",
    "    l_i = 1\n",
    "        \n",
    "    normalizing_weight = 1 #/ len(inputs['L_neighbors'])\n",
    "        \n",
    "    l_j = inputs['L_neighbors']\n",
    "    \n",
    "    sum_l_j = sum(l_j)\n",
    "    adjusted_sum_l_j = sum_l_j * normalizing_weight\n",
    "\n",
    "    w_ij_l = normalizing_weight\n",
    "        \n",
    "    inputs = {\n",
    "        'l_i': l_i,\n",
    "        'l_j_list': l_j,  \n",
    "        'adjusted_sum_l_j': adjusted_sum_l_j,\n",
    "        'w_ij_l': w_ij_l \n",
    "    }\n",
    "        \n",
    "    return f_L_i_given_stuff(inputs, params_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "827756b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress:  0.0\n",
      "progress:  0.02\n",
      "progress:  0.04\n",
      "progress:  0.06\n",
      "progress:  0.08\n",
      "progress:  0.1\n",
      "progress:  0.12\n",
      "progress:  0.14\n",
      "progress:  0.16\n",
      "progress:  0.18\n",
      "progress:  0.2\n",
      "progress:  0.22\n",
      "progress:  0.24\n",
      "progress:  0.26\n",
      "progress:  0.28\n",
      "progress:  0.3\n",
      "progress:  0.32\n",
      "progress:  0.34\n",
      "progress:  0.36\n",
      "progress:  0.38\n",
      "progress:  0.4\n",
      "progress:  0.42\n",
      "progress:  0.44\n",
      "progress:  0.46\n",
      "progress:  0.48\n",
      "progress:  0.5\n",
      "progress:  0.52\n",
      "progress:  0.54\n",
      "progress:  0.56\n",
      "progress:  0.58\n",
      "progress:  0.6\n",
      "progress:  0.62\n",
      "progress:  0.64\n",
      "progress:  0.66\n",
      "progress:  0.68\n",
      "progress:  0.7\n",
      "progress:  0.72\n",
      "progress:  0.74\n",
      "progress:  0.76\n",
      "progress:  0.78\n",
      "progress:  0.8\n",
      "progress:  0.82\n",
      "progress:  0.84\n",
      "progress:  0.86\n",
      "progress:  0.88\n",
      "progress:  0.9\n",
      "progress:  0.92\n",
      "progress:  0.94\n",
      "progress:  0.96\n",
      "progress:  0.98\n",
      "progress:  0.0\n",
      "progress:  0.02\n",
      "progress:  0.04\n",
      "progress:  0.06\n",
      "progress:  0.08\n",
      "progress:  0.1\n",
      "progress:  0.12\n",
      "progress:  0.14\n",
      "progress:  0.16\n",
      "progress:  0.18\n",
      "progress:  0.2\n",
      "progress:  0.22\n",
      "progress:  0.24\n",
      "progress:  0.26\n",
      "progress:  0.28\n",
      "progress:  0.3\n",
      "progress:  0.32\n",
      "progress:  0.34\n",
      "progress:  0.36\n",
      "progress:  0.38\n",
      "progress:  0.4\n",
      "progress:  0.42\n",
      "progress:  0.44\n",
      "progress:  0.46\n",
      "progress:  0.48\n",
      "progress:  0.5\n",
      "progress:  0.52\n",
      "progress:  0.54\n",
      "progress:  0.56\n",
      "progress:  0.58\n",
      "progress:  0.6\n",
      "progress:  0.62\n",
      "progress:  0.64\n",
      "progress:  0.66\n",
      "progress:  0.68\n",
      "progress:  0.7\n",
      "progress:  0.72\n",
      "progress:  0.74\n",
      "progress:  0.76\n",
      "progress:  0.78\n",
      "progress:  0.8\n",
      "progress:  0.82\n",
      "progress:  0.84\n",
      "progress:  0.86\n",
      "progress:  0.88\n",
      "progress:  0.9\n",
      "progress:  0.92\n",
      "progress:  0.94\n",
      "progress:  0.96\n",
      "progress:  0.98\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Y_A1 = gibbs_sampler_1(n_samples=40000, burn_in=10000, network=network, f_Yi=hat_f_Yi, f_Li=hat_f_Li, \n",
    "                       verbose=True, A_val=1)\n",
    "\n",
    "Y_A0 = gibbs_sampler_1(n_samples=40000, burn_in=10000, network=network, f_Yi=hat_f_Yi, f_Li=hat_f_Li, \n",
    "                       verbose=True, A_val=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "3231cc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = [beta_i_a(Y_A1, i, 3) - beta_i_a(Y_A0, i, 3) for i in range(0, 1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "27f3c125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.05987370631468427"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69179250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1ee34f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "ab02743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SOURCE = \"../data/simulation_autog/\"\n",
    "TRUE_MODEL = \"UUU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c2af8098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get network (UUU) data\n",
    "network_path = os.path.join(DATA_SOURCE, 'network.pkl')\n",
    "sample_data_path = os.path.join(DATA_SOURCE, f\"{TRUE_MODEL}_sample.csv\")\n",
    "ind_set_path = os.path.join(DATA_SOURCE, '1_ind_set.csv')\n",
    "\n",
    "with open(network_path, 'rb') as file:\n",
    "    network = pickle.load(file)\n",
    "\n",
    "GM_sample = pd.read_csv(sample_data_path)\n",
    "ind_set = pd.read_csv(ind_set_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "242470b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_df = df_for_estimation(network=network, ind_set=ind_set, sample=GM_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0d378ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.23724727e-07  3.23724727e-07]\n",
      "[0.4628976  1.97511989]\n"
     ]
    }
   ],
   "source": [
    "# Example from meeting with Rohit\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import expit\n",
    "\n",
    "def f(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "\n",
    "guess = [-10, 10]\n",
    "result = minimize(f, x0=guess, method=\"L-BFGS-B\")\n",
    "print(result.x)\n",
    "\n",
    "\n",
    "X = np.random.normal(0, 1, 2000)\n",
    "Y = np.random.binomial(1, expit(0.5 + 2*X), 2000)\n",
    "\n",
    "def nll(theta, X, Y):\n",
    "    pY1 = expit(theta[0] + theta[1]*X)\n",
    "    pY = np.log(Y*pY1 + (1-Y)*(1-pY1))\n",
    "    return -np.sum(pY)\n",
    "\n",
    "result = minimize(nll, x0=np.random.uniform(-1, 1, 2), args=(X, Y))\n",
    "print(result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e5cd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR AUTO GAUSSIAN MODEL ###\n",
    "\n",
    "def G_i(y_i, a_i, l_i, adjusted_sum_a_j, adjusted_sum_l_j, params):\n",
    "    beta_0, betah_1, beta_2, beta_3, beta_4, sigma2_y = params[:-1]\n",
    "    mu_y_i = beta_0 + beta_1*a_i + beta_2*l_i + beta_3*adjusted_sum_a_j + beta_4*adjusted_sum_l_j\n",
    "    return -(1/(2*sigma2_y)) * (y_i - 2*mu_y_i)\n",
    "\n",
    "def theta_ij(w_ij_y, params):\n",
    "    theta = params[-1]\n",
    "    return w_ij_y * theta\n",
    "\n",
    "def U_i(data_i, params, y_i=None):\n",
    "    # we allow the caller to pass in y_i separate from data_i\n",
    "    # so that when evaluating the denominator it is easier.\n",
    "    if y_i == None:\n",
    "        y_i = data_i['y_i']\n",
    "    G_i_output = G_i(y_i=y_i, \n",
    "                      a_i=data_i['a_i'], \n",
    "                      l_i=data_i['l_i'], \n",
    "                      adjusted_sum_a_j=data_i['adjusted_sum_a_j'], \n",
    "                      adjusted_sum_l_j=data_i['adjusted_sum_l_j'], \n",
    "                      params=params)\n",
    "    \n",
    "    second_term = 0\n",
    "    for y_j in data_i['y_j_dict'].values():\n",
    "        second_term += y_i * y_j * theta_ij(data_i['w_ij_yw_ij_theta'], params)\n",
    "    \n",
    "    return y_i * G_i_output + second_term\n",
    "\n",
    "def f_Y_i_given_stuff(data_i, params):\n",
    "    numerator = math.exp(U_i(data_i, params))\n",
    "    \n",
    "    # define a lambda function for what we want to integrate over\n",
    "    integrand = lambda y_i: math.exp(U_i(data_i, params, y_i))\n",
    "    \n",
    "    # perform numerical integration over the range of y_i\n",
    "    range_min, range_max = -np.inf, np.inf \n",
    "    denominator, abserr = quad(integrand, range_min, range_max)\n",
    "    \n",
    "    return numerator / denominator\n",
    "\n",
    "def neg_log_coding_likelihood(params, Y_est_data):\n",
    "    log_likelihoods = Y_est_data.apply(lambda row: np.log(f_Y_i_given_stuff(row, params)), axis=1)\n",
    "    print(-np.sum(log_likelihoods))\n",
    "    return -np.sum(log_likelihoods)\n",
    "\n",
    "def optimize_params(initial_params, Y_est_data):\n",
    "    result = minimize(\n",
    "        fun=lambda params: neg_log_coding_likelihood(params, Y_est_data),\n",
    "        x0=initial_params,\n",
    "        method='L-BFGS-B'\n",
    "    )\n",
    "    return result.x if result.success else None\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
