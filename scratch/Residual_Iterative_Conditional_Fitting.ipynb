{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "id": "uAJMwbff-CaF"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import networkx as nx\n",
    "import random\n",
    "from main import maximal_independent_set\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "id": "3i6GL9MyEQTY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2m/s6xvfp8x29j9m9pl6w7jn8hh0000gn/T/ipykernel_51259/2237531497.py:11: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adj_matrix = nx.adjacency_matrix(g).toarray()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[287], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m cov_mat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(network \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, cov_mat, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     31\u001b[0m np\u001b[38;5;241m.\u001b[39mfill_diagonal(cov_mat, variance)\n\u001b[0;32m---> 33\u001b[0m L \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultivariate_normal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mmtrand.pyx:4155\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.multivariate_normal\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/numpy/linalg/linalg.py:1657\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         gufunc \u001b[38;5;241m=\u001b[39m _umath_linalg\u001b[38;5;241m.\u001b[39msvd_n_s\n\u001b[1;32m   1656\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->DdD\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->ddd\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1657\u001b[0m u, s, vh \u001b[38;5;241m=\u001b[39m \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1658\u001b[0m u \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1659\u001b[0m s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mastype(_realType(result_t), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# My Implementation (Full Interference Setting)\n",
    "\n",
    "def random_network_adjacency_matrix(n, min_neighbors, max_neighbors):\n",
    "    while True:\n",
    "        degree_sequence = [random.randint(min_neighbors, max_neighbors) for _ in range(n)]\n",
    "        if sum(degree_sequence) % 2 == 0:\n",
    "            break\n",
    "    g = nx.configuration_model(degree_sequence)\n",
    "    g = nx.Graph(g)\n",
    "    g.remove_edges_from(nx.selfloop_edges(g))\n",
    "    adj_matrix = nx.adjacency_matrix(g).toarray()\n",
    "\n",
    "    return nx.to_dict_of_lists(g), adj_matrix\n",
    "\n",
    "# random network:\n",
    "n_samples = 10000\n",
    "network_dict, network = random_network_adjacency_matrix(n_samples, 0, 5)\n",
    "\n",
    "var_U = 2\n",
    "var_eL = 0.5\n",
    "beta = 1\n",
    "\n",
    "covariance = beta * beta * var_U\n",
    "\n",
    "# Update for variance calculation on diagonals\n",
    "neighbors = np.sum(network, axis=1)\n",
    "variance = neighbors * covariance + var_eL\n",
    "\n",
    "cov_mat = np.full(network.shape, covariance)\n",
    "cov_mat = np.where(network > 0, cov_mat, 0)\n",
    "np.fill_diagonal(cov_mat, variance)\n",
    "\n",
    "L = np.random.multivariate_normal([0]*n_samples, cov_mat, size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZctcB8IbPjEx",
    "outputId": "f1da2d24-f510-43c7-d7f5-47b330deb093"
   },
   "outputs": [],
   "source": [
    "ind_set = maximal_independent_set.maximal_n_apart_independent_set(network_dict, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(network, ind_set, L):\n",
    "    df = pd.DataFrame(L.T, columns=[\"L_i\"])\n",
    "    df_subset = df.iloc[list(ind_set)]\n",
    "    df_subset['nb_count'] = df_subset.apply(lambda x: len(network[x.name]), axis=1)\n",
    "    return df_subset\n",
    "\n",
    "def custom_nll(params, data):\n",
    "    sigma_multiplier, sigma_constant = params\n",
    "    mu = 0\n",
    "    sigma_values = sigma_multiplier * data['nb_count'] + sigma_constant\n",
    "    ll = -np.sum(0.5 * np.log(2 * np.pi * sigma_values**2) + ((data['L_i'] - mu)**2) / (2 * sigma_values**2))\n",
    "    return -ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2m/s6xvfp8x29j9m9pl6w7jn8hh0000gn/T/ipykernel_51259/2771919432.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_subset['nb_count'] = df_subset.apply(lambda x: len(network[x.name]), axis=1)\n"
     ]
    }
   ],
   "source": [
    "data = build_dataset(network_dict, ind_set, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimate: [ 8.02280749e-01 -2.19617953e-07]\n",
      "true: 2 0.5\n"
     ]
    }
   ],
   "source": [
    "# Our Custom MLE with variance depending on number of neighbors\n",
    "\n",
    "print(\"estimate:\", minimize(custom_nll, [0.1, 0.1], args=(data), method=\"L-BFGS-B\").x)\n",
    "print(\"true:\", covariance, var_eL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[337, 210, 172, 150, 96]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(data[data['nb_count'] == i]) for i in range(0, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "VIlxmFaNCKO2"
   },
   "outputs": [],
   "source": [
    "# questions:\n",
    "# 1. return 0.5 / n * np.linalg.norm(L[:, var_index] - np.dot(Z, params)) ** 2 in least_squares_loss doesnt seem to be following the\n",
    "# paper's implementation.\n",
    "\n",
    "# 2. why can't we just directly use the empirical covariance matrix on all variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xnYaUYvMJcTz",
    "outputId": "d8d3b147-9d1a-4d49-8c59-26e7878eb456"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.014116302093843 1.9611859638356997 2.0133962451971392\n"
     ]
    }
   ],
   "source": [
    "true_cov_mat = np.array([[2, 0.9, 0.3],\n",
    "                        [0.9, 2, 0.7],\n",
    "                        [0.3, 0.7, 2]])\n",
    "L = np.random.multivariate_normal([0,0,0], true_cov_mat, size=10000)\n",
    "L1 = L[:,0]\n",
    "L2 = L[:,1]\n",
    "L3 = L[:,2]\n",
    "print(np.var(L1), np.var(L2), np.var(L3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iBzVW5C4JhAV",
    "outputId": "4021d4ba-5b8c-42f1-b43a-978cf218ea0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.41890978 0.1637278 ]\n",
      " [0.1637278  0.71993856]]\n"
     ]
    }
   ],
   "source": [
    "n_samples = 5000\n",
    "U1 = np.random.normal(0, 0.8, n_samples)\n",
    "U2 = np.random.normal(0, 0.8, n_samples)\n",
    "U3 = np.random.normal(0, 0.8, n_samples)\n",
    "\n",
    "noise_L1 = np.random.normal(0, 0.5, n_samples)\n",
    "noise_L2 = np.random.normal(0, 0.5, n_samples)\n",
    "noise_L3 = np.random.normal(0, 0.5, n_samples)\n",
    "beta = 0.5\n",
    "L1 = beta * U1 + noise_L1\n",
    "L2 = beta * U1 + beta * U2 + beta * U3 + noise_L2\n",
    "L3 = beta * U3 + noise_L3\n",
    "\n",
    "L = np.array([L1, L2, L3])\n",
    "print(np.cov(L1, L2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JNbM_-l5MtO7",
    "outputId": "22e9cafe-fd14-4704-b49c-2aa1123258f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4066664483208884\n",
      "0.719150370899255\n"
     ]
    }
   ],
   "source": [
    "print(1 * np.var(U1) * beta**2 + np.var(noise_L1))\n",
    "print(3 * np.var(U1) * beta**2 + np.var(noise_L1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "id": "KXyrKKHACon1",
    "outputId": "5d0ca37c-631e-4a18-fc77-8d0a8fab2ce2"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 2 is different from 4999)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-fe77a881615d>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mepsilon_minusi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mZ_minusi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon_minusi\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0momega_minusii_inv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_minusi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 2 is different from 4999)"
     ]
    }
   ],
   "source": [
    "\n",
    "# true_cov_mat = np.array([[1, 0.5, 0],\n",
    "#                         [0.5, 1, 0.7],\n",
    "#                         [0, 0.7, 1]])\n",
    "# L = np.random.multivariate_normal([0,0,0], true_cov_mat, size=5000)\n",
    "# L1 = L[:,0]\n",
    "# L2 = L[:,1]\n",
    "# L3 = L[:,2]\n",
    "eps_L1 = L1 - np.mean(L1)\n",
    "eps_L2 = L2 - np.mean(L2)\n",
    "eps_L3 = L3 - np.mean(L3)\n",
    "\n",
    "def least_squares_loss(params, L, Z, var_index):\n",
    "    n, d = L.shape\n",
    "    return 0.5 * n * np.linalg.norm(L[:, var_index] - np.dot(Z, params)) ** 2\n",
    "    # return 0.5 / n * np.linalg.norm(L[:, var_index] - np.dot(Z, params)) ** 2\n",
    "\n",
    "d = 3\n",
    "max_iter = 10\n",
    "\n",
    "\n",
    "# random guess for cov mat\n",
    "cov_mat = np.array([[0.0, 0.0, 0.0],\n",
    "                    [0.0, 0.0, 0.0],\n",
    "                    [0.0, 0.0, 0.0]])\n",
    "\n",
    "var = np.array([[np.var(eps_L1), 0.0, 0.0],\n",
    "                [0.0, np.var(eps_L2), 0.0],\n",
    "                [0.0, 0.0, np.var(eps_L3)]])\n",
    "\n",
    "for iter in range(max_iter):\n",
    "\n",
    "    for var_index in range(d):\n",
    "        zero_param_bidirected = {}\n",
    "\n",
    "        omega = cov_mat + var\n",
    "        omega_minusi = np.delete(omega, var_index, axis=0)\n",
    "        omega_minusii = np.delete(omega_minusi, var_index, axis=1)\n",
    "        omega_minusii_inv = np.linalg.inv(omega_minusii)\n",
    "\n",
    "        epsilon = L.copy()\n",
    "        epsilon_minusi = np.delete(epsilon, var_index, axis=1)\n",
    "\n",
    "        Z_minusi = epsilon_minusi @ omega_minusii_inv.T\n",
    "        Z = np.insert(Z_minusi, var_index, 0, axis=1)\n",
    "\n",
    "        sol = minimize(least_squares_loss,\n",
    "                    np.zeros(d),\n",
    "                    args=(L, Z, var_index))\n",
    "\n",
    "        cov_mat[:, var_index] = sol.x\n",
    "        cov_mat[var_index, :] = sol.x\n",
    "        var[var_index, var_index] = np.var(L[:, var_index])\n",
    "        print()\n",
    "\n",
    "print(\"cov mat:\", cov_mat)\n",
    "print(\"var:\", var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t3Xpgxo-3uWg",
    "outputId": "b0e4b8b2-f098-482f-b4d6-d4f6256db532"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.97020581, -0.00972078],\n",
       "       [-0.00972078,  1.0177522 ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(L[:,0], L[:,2])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
